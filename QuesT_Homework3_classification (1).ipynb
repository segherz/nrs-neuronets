{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0fOWhqwW-AT",
        "outputId": "440d2735-457c-4adb-e916-f5ed262af2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.21.6)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.7.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0.post1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install nltk\n",
        "!pip install tqdm\n",
        "!pip install seaborn\n",
        "!pip install numpy\n",
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3wugeOHW-AV",
        "outputId": "a0924526-e4f5-465e-b766-c217842e3fab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9XIrxSmW-AX"
      },
      "source": [
        "# Скачиваем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep1FB3IBW-AY",
        "outputId": "bdab9626-ee9c-45ca-a2db-284771afdfba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-27 18:15:39--  https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28717126 (27M) [text/plain]\n",
            "Saving to: ‘answers_subsample.csv.2’\n",
            "\n",
            "answers_subsample.c 100%[===================>]  27.39M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-11-27 18:15:40 (244 MB/s) - ‘answers_subsample.csv.2’ saved [28717126/28717126]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "BWA7IClKW-Aa"
      },
      "outputs": [],
      "source": [
        "# если ругается на то, что нет wget\n",
        "# !apt-get install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJpFTPpsW-Ac",
        "outputId": "3b6a9243-8b91-45da-f10f-e92ee960c0b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4514240\n",
            "-rw-r--r-- 1 root root   28717126 Nov 27 17:16 answers_subsample.csv\n",
            "-rw-r--r-- 1 root root   28717126 Nov 27 17:34 answers_subsample.csv.1\n",
            "-rw-r--r-- 1 root root   28717126 Nov 27 18:15 answers_subsample.csv.2\n",
            "-rw-r--r-- 1 root root 4536408847 Jan 18  2019 cc.ru.300.vec\n",
            "drwxr-xr-x 1 root root       4096 Nov 22 00:14 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "qmzaEwy9W-Ae"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "BbDKxq4EW-Ag"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('answers_subsample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hcAdsbS7W-Ai",
        "outputId": "7b26ef06-9efd-4206-bf96-a0383293e081"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                               text\n",
              "0       business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1            law  Может ли срочник перевестись на контракт после...\n",
              "2       business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3       business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4            law                 часть 1 статья 158 похитил телефон\n",
              "...          ...                                                ...\n",
              "237774     relax                                  елку нарядили? =)\n",
              "237775       law  Имеется переработка при 75% ставки, отгулы не ...\n",
              "237776      food  Попробовала варить рис с половиной кубика для ...\n",
              "237777      food  Почему рекоменд... Почему рекомендуют есть фру...\n",
              "237778  business  Подскажите какие риски бывают в семье среднест...\n",
              "\n",
              "[237779 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3d122cd-cdda-44af-a47f-6a18585ba53e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237774</th>\n",
              "      <td>relax</td>\n",
              "      <td>елку нарядили? =)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237775</th>\n",
              "      <td>law</td>\n",
              "      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237776</th>\n",
              "      <td>food</td>\n",
              "      <td>Попробовала варить рис с половиной кубика для ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237777</th>\n",
              "      <td>food</td>\n",
              "      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237778</th>\n",
              "      <td>business</td>\n",
              "      <td>Подскажите какие риски бывают в семье среднест...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237779 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3d122cd-cdda-44af-a47f-6a18585ba53e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f3d122cd-cdda-44af-a47f-6a18585ba53e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f3d122cd-cdda-44af-a47f-6a18585ba53e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90tXLjfsW-Aj",
        "outputId": "6e99b27c-4a03-4f41-abd2-67895389aa37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "law         29.793211\n",
              "relax       22.016242\n",
              "business    19.309527\n",
              "food        18.367055\n",
              "love        10.513965\n",
              "Name: category, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ],
      "source": [
        "data.category.value_counts() * 100 / data.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfHbifWIW-Al"
      },
      "source": [
        "# Предобученные эмбеддинги\n",
        "[Источник](https://fasttext.cc/docs/en/crawl-vectors.html)  \n",
        "Вы можете взять любые word2vec подобные эмббединги. Если вы хотите использовать elmo, bert, etc сначала попробуйте с word2vec подобными эмббедингами, а потом можете перейти к более сложным моделям.  \n",
        "Ниже мы сначала скачиваем, а потом распоковываем эмбеддинги."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "PVhCzM3LW-Al"
      },
      "outputs": [],
      "source": [
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "# !gzip -d cc.ru.300.vec.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJcT1qPZW-An",
        "outputId": "0d4cdb5c-910f-4c3a-a528-354886e2a53e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4514240\n",
            "-rw-r--r-- 1 root root   28717126 Nov 27 17:16 answers_subsample.csv\n",
            "-rw-r--r-- 1 root root   28717126 Nov 27 17:34 answers_subsample.csv.1\n",
            "-rw-r--r-- 1 root root   28717126 Nov 27 18:15 answers_subsample.csv.2\n",
            "-rw-r--r-- 1 root root 4536408847 Jan 18  2019 cc.ru.300.vec\n",
            "drwxr-xr-x 1 root root       4096 Nov 22 00:14 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "M0lwyZUFW-Ap"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "QQpX51Y4W-Aq"
      },
      "outputs": [],
      "source": [
        "# потом можете добавить свою предобработку\n",
        "\n",
        "def process_text(text):\n",
        "    \n",
        "    words = wordpunct_tokenize(text.lower())\n",
        "    \n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyI2erCDW-Ar",
        "outputId": "1ed01583-7fbb-4536-defd-6feb386b9726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/237779 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|▍         | 10005/237779 [00:00<00:02, 100040.08it/s]\u001b[A\n",
            "  9%|▊         | 20775/237779 [00:00<00:02, 104537.58it/s]\u001b[A\n",
            " 13%|█▎        | 31248/237779 [00:00<00:01, 104619.79it/s]\u001b[A\n",
            " 18%|█▊        | 41861/237779 [00:00<00:01, 105211.94it/s]\u001b[A\n",
            " 22%|██▏       | 52423/237779 [00:00<00:01, 105355.40it/s]\u001b[A\n",
            " 26%|██▋       | 62959/237779 [00:00<00:02, 80696.19it/s] \u001b[A\n",
            " 30%|███       | 71799/237779 [00:00<00:02, 77124.27it/s]\u001b[A\n",
            " 34%|███▎      | 80024/237779 [00:00<00:02, 68034.33it/s]\u001b[A\n",
            " 37%|███▋      | 87289/237779 [00:01<00:02, 64776.85it/s]\u001b[A\n",
            " 41%|████      | 97508/237779 [00:01<00:01, 74072.74it/s]\u001b[A\n",
            " 45%|████▌     | 107808/237779 [00:01<00:01, 81649.85it/s]\u001b[A\n",
            " 49%|████▉     | 117687/237779 [00:01<00:01, 86315.84it/s]\u001b[A\n",
            " 54%|█████▍    | 128018/237779 [00:01<00:01, 91073.34it/s]\u001b[A\n",
            " 58%|█████▊    | 138415/237779 [00:01<00:01, 94756.46it/s]\u001b[A\n",
            " 62%|██████▏   | 148524/237779 [00:01<00:00, 96589.65it/s]\u001b[A\n",
            " 67%|██████▋   | 158430/237779 [00:01<00:00, 97306.52it/s]\u001b[A\n",
            " 71%|███████   | 168724/237779 [00:01<00:00, 98965.73it/s]\u001b[A\n",
            " 75%|███████▌  | 178704/237779 [00:02<00:00, 98367.81it/s]\u001b[A\n",
            " 80%|███████▉  | 189358/237779 [00:02<00:00, 100782.53it/s]\u001b[A\n",
            " 84%|████████▍ | 199760/237779 [00:02<00:00, 101741.14it/s]\u001b[A\n",
            " 88%|████████▊ | 209967/237779 [00:02<00:00, 97432.62it/s] \u001b[A\n",
            " 92%|█████████▏| 219770/237779 [00:02<00:00, 96586.30it/s]\u001b[A\n",
            "100%|██████████| 237779/237779 [00:02<00:00, 91473.98it/s]\n"
          ]
        }
      ],
      "source": [
        "word2freq = {}\n",
        "lengths = []\n",
        "\n",
        "for text in tqdm(data.text):\n",
        "    \n",
        "    words = process_text(text)\n",
        "    \n",
        "    lengths.append(len(words))\n",
        "    \n",
        "    for word in words:\n",
        "        \n",
        "        if word in word2freq:\n",
        "            word2freq[word] += 1\n",
        "        else:\n",
        "            word2freq[word] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "FGzDm0ptW-At"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "iZBR-aYDW-Av",
        "outputId": "635d960d-10fd-483b-f357-5da7fb20ef08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbef82b9290>"
            ]
          },
          "metadata": {},
          "execution_count": 170
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "plt.title('Распределение длин слов в текстах')\n",
        "plt.xlabel('Длина предложения')\n",
        "plt.ylabel('Доля')\n",
        "sns.distplot(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OBzmPqXIW-Aw",
        "outputId": "ce28c30a-302e-44eb-e912-4ab56624b875"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'99.66 % наших текстов входят в промежуток от 3 до 32 слов'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 171
        }
      ],
      "source": [
        "upper_threshold = 32\n",
        "lower_threshold = 3\n",
        "\n",
        "correct_percent = len([sent_len for sent_len in lengths \n",
        "                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n",
        "\n",
        "'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbSer_0bW-Ay",
        "outputId": "964794e0-af53-42dc-ab4d-f14d9223c22f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152179"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ],
      "source": [
        "len(word2freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "szg6XD3EW-Az",
        "outputId": "593b5096-e95b-464b-9806-d0a8ed8261f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'114332 слов, которые встречались 3 и менее раз'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 173
        }
      ],
      "source": [
        "'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZbOg0FqW-A1"
      },
      "source": [
        "# Читаем файл с эмбеддингами\n",
        "### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\n",
        "Поэтому прочитаем только те слова, которые мы знаем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "T1Yx_qr-W-A2"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLEgfnaWW-A4",
        "outputId": "7aef1c52-b59f-49ce-da2a-4099f1a45282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Read word2vec:   0%|          | 0/2000000 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  11%|█         | 23744/214001 [01:06<08:55, 355.38it/s, train_loss=1.08] \n",
            "\n",
            "Read word2vec:   0%|          | 2574/2000000 [00:00<02:38, 12641.85it/s]\u001b[A\n",
            "Read word2vec:   0%|          | 3839/2000000 [00:00<02:46, 12017.80it/s]\u001b[A\n",
            "Read word2vec:   0%|          | 5149/2000000 [00:00<02:40, 12426.56it/s]\u001b[A\n",
            "Read word2vec:   0%|          | 6619/2000000 [00:00<02:30, 13226.15it/s]\u001b[A\n",
            "Read word2vec:   0%|          | 7946/2000000 [00:00<02:34, 12884.32it/s]\u001b[A\n",
            "Read word2vec:   0%|          | 9417/2000000 [00:00<02:27, 13461.66it/s]\u001b[A\n",
            "Read word2vec:   1%|          | 10935/2000000 [00:00<02:22, 13995.02it/s]\u001b[A\n",
            "Read word2vec:   1%|          | 12339/2000000 [00:00<02:26, 13565.68it/s]\u001b[A\n",
            "Read word2vec:   1%|          | 13701/2000000 [00:01<02:30, 13213.89it/s]\u001b[A\n",
            "Read word2vec:   1%|          | 15027/2000000 [00:01<02:31, 13099.80it/s]\u001b[A\n",
            "Read word2vec:   1%|          | 16340/2000000 [00:01<02:36, 12638.34it/s]\u001b[A\n",
            "Read word2vec:   1%|          | 17608/2000000 [00:01<03:14, 10211.39it/s]\u001b[A\n",
            "Read word2vec:   1%|          | 18702/2000000 [00:01<03:29, 9450.04it/s] \u001b[A\n",
            "Read word2vec:   1%|          | 19702/2000000 [00:01<03:46, 8741.12it/s]\u001b[A\n",
            "Read word2vec:   1%|          | 20617/2000000 [00:01<04:04, 8110.45it/s]\u001b[A\n",
            "Read word2vec:   1%|          | 21457/2000000 [00:02<04:45, 6921.49it/s]\u001b[A\n",
            "Read word2vec:   1%|          | 22262/2000000 [00:02<04:35, 7173.39it/s]\u001b[A\n",
            "Read word2vec:   1%|          | 23139/2000000 [00:02<04:21, 7560.61it/s]\u001b[A\n",
            "Read word2vec:   1%|          | 23936/2000000 [00:02<04:17, 7663.31it/s]\u001b[A\n",
            "Read word2vec:   1%|          | 24728/2000000 [00:02<04:24, 7462.75it/s]\u001b[A\n",
            "Read word2vec:   1%|▏         | 25492/2000000 [00:02<04:36, 7136.92it/s]\u001b[A\n",
            "Read word2vec:   1%|▏         | 26219/2000000 [00:02<05:01, 6550.31it/s]\u001b[A\n",
            "Read word2vec:   1%|▏         | 26889/2000000 [00:02<05:38, 5833.81it/s]\u001b[A\n",
            "Read word2vec:   1%|▏         | 27621/2000000 [00:02<05:18, 6200.40it/s]\u001b[A\n",
            "Read word2vec:   1%|▏         | 28263/2000000 [00:03<05:18, 6190.98it/s]\u001b[A\n",
            "Read word2vec:   1%|▏         | 29008/2000000 [00:03<05:01, 6529.91it/s]\u001b[A\n",
            "Read word2vec:   1%|▏         | 29782/2000000 [00:03<04:46, 6865.69it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 30482/2000000 [00:03<05:10, 6349.20it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 31133/2000000 [00:03<05:43, 5730.29it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 31726/2000000 [00:03<06:53, 4764.49it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 32238/2000000 [00:03<06:52, 4775.50it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 32879/2000000 [00:03<06:19, 5178.72it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 33602/2000000 [00:04<05:44, 5712.56it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 34377/2000000 [00:04<05:13, 6265.37it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 35210/2000000 [00:04<04:47, 6840.04it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 35995/2000000 [00:04<04:35, 7127.20it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 36854/2000000 [00:04<04:22, 7470.16it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 37665/2000000 [00:04<04:16, 7654.60it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 38563/2000000 [00:04<04:03, 8041.28it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 39381/2000000 [00:04<04:02, 8079.31it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 40289/2000000 [00:04<03:54, 8366.11it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 41130/2000000 [00:04<03:55, 8308.91it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 41964/2000000 [00:05<03:57, 8227.34it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 42923/2000000 [00:05<03:46, 8628.86it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 43788/2000000 [00:05<03:51, 8440.66it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 44635/2000000 [00:05<03:54, 8353.64it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 45476/2000000 [00:05<03:54, 8343.82it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 46312/2000000 [00:05<04:05, 7955.73it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 47112/2000000 [00:05<04:18, 7567.38it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 47875/2000000 [00:05<04:27, 7298.40it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 48805/2000000 [00:05<04:09, 7814.69it/s]\u001b[A\n",
            "Read word2vec:   2%|▏         | 49776/2000000 [00:05<03:53, 8350.57it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 50619/2000000 [00:06<03:58, 8163.20it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 51442/2000000 [00:06<04:54, 6625.39it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 52306/2000000 [00:06<04:33, 7125.59it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 53271/2000000 [00:06<04:10, 7786.74it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 54227/2000000 [00:06<03:55, 8269.32it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 55185/2000000 [00:06<03:45, 8636.19it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 56075/2000000 [00:06<03:50, 8421.77it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 57084/2000000 [00:06<03:38, 8893.50it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 57990/2000000 [00:07<03:54, 8274.35it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 58837/2000000 [00:07<04:17, 7532.65it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 60003/2000000 [00:07<03:45, 8614.89it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 60896/2000000 [00:07<03:56, 8191.84it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 61970/2000000 [00:07<03:38, 8875.81it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 62952/2000000 [00:07<03:32, 9127.52it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 63919/2000000 [00:07<03:28, 9280.36it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 64862/2000000 [00:07<03:38, 8858.08it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 65938/2000000 [00:07<03:31, 9157.26it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 66864/2000000 [00:08<03:48, 8453.14it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 67941/2000000 [00:08<03:32, 9077.98it/s]\u001b[A\n",
            "Read word2vec:   3%|▎         | 68973/2000000 [00:08<03:24, 9419.98it/s]\u001b[A\n",
            "Read word2vec:   4%|▎         | 70052/2000000 [00:08<03:16, 9809.16it/s]\u001b[A\n",
            "Read word2vec:   4%|▎         | 71046/2000000 [00:08<03:25, 9367.04it/s]\u001b[A\n",
            "Read word2vec:   4%|▎         | 71995/2000000 [00:08<03:25, 9390.45it/s]\u001b[A\n",
            "Read word2vec:   4%|▎         | 73099/2000000 [00:08<03:15, 9860.27it/s]\u001b[A\n",
            "Read word2vec:   4%|▎         | 74094/2000000 [00:08<03:26, 9312.02it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 75037/2000000 [00:08<03:56, 8128.62it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 76140/2000000 [00:09<03:36, 8879.04it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 77112/2000000 [00:09<03:31, 9104.04it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 78049/2000000 [00:09<03:53, 8230.06it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 79104/2000000 [00:09<03:37, 8837.83it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 80034/2000000 [00:09<03:36, 8866.76it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 80943/2000000 [00:09<03:35, 8900.69it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 81849/2000000 [00:09<03:39, 8740.46it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 82734/2000000 [00:09<04:03, 7858.39it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 83542/2000000 [00:09<04:15, 7510.95it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 84384/2000000 [00:10<04:07, 7751.80it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 85343/2000000 [00:10<03:51, 8256.74it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 86484/2000000 [00:10<03:29, 9114.70it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 87717/2000000 [00:10<03:10, 10035.04it/s]\u001b[A\n",
            "Read word2vec:   4%|▍         | 89016/2000000 [00:10<02:55, 10892.54it/s]\u001b[A\n",
            "Read word2vec:   5%|▍         | 90318/2000000 [00:10<02:45, 11515.07it/s]\u001b[A\n",
            "Read word2vec:   5%|▍         | 91481/2000000 [00:10<02:52, 11058.99it/s]\u001b[A\n",
            "Read word2vec:   5%|▍         | 92598/2000000 [00:10<03:03, 10386.66it/s]\u001b[A\n",
            "Read word2vec:   5%|▍         | 93651/2000000 [00:10<03:12, 9919.99it/s] \u001b[A\n",
            "Read word2vec:   5%|▍         | 94655/2000000 [00:11<03:31, 9016.99it/s]\u001b[A\n",
            "Read word2vec:   5%|▍         | 95846/2000000 [00:11<03:14, 9773.92it/s]\u001b[A\n",
            "Read word2vec:   5%|▍         | 96924/2000000 [00:11<03:09, 10047.59it/s]\u001b[A\n",
            "Read word2vec:   5%|▍         | 98280/2000000 [00:11<02:52, 11030.94it/s]\u001b[A\n",
            "Read word2vec:   5%|▍         | 99422/2000000 [00:11<02:52, 10996.57it/s]\u001b[A\n",
            "Read word2vec:   5%|▌         | 100615/2000000 [00:11<02:50, 11160.90it/s]\u001b[A\n",
            "Read word2vec:   5%|▌         | 101742/2000000 [00:11<03:12, 9847.60it/s] \u001b[A\n",
            "Read word2vec:   5%|▌         | 102849/2000000 [00:11<03:06, 10167.87it/s]\u001b[A\n",
            "Read word2vec:   5%|▌         | 103894/2000000 [00:11<03:44, 8435.30it/s] \u001b[A\n",
            "Read word2vec:   5%|▌         | 104802/2000000 [00:12<03:52, 8163.86it/s]\u001b[A\n",
            "Read word2vec:   5%|▌         | 105734/2000000 [00:12<03:44, 8450.23it/s]\u001b[A\n",
            "Read word2vec:   5%|▌         | 106786/2000000 [00:12<03:30, 8990.50it/s]\u001b[A\n",
            "Read word2vec:   5%|▌         | 107753/2000000 [00:12<03:26, 9166.47it/s]\u001b[A\n",
            "Read word2vec:   5%|▌         | 108695/2000000 [00:12<03:39, 8617.83it/s]\u001b[A\n",
            "Read word2vec:   6%|▌         | 110065/2000000 [00:12<03:09, 9998.77it/s]\u001b[A\n",
            "Read word2vec:   6%|▌         | 111187/2000000 [00:12<03:02, 10339.87it/s]\u001b[A\n",
            "Read word2vec:   6%|▌         | 112245/2000000 [00:12<03:17, 9570.53it/s] \u001b[A\n",
            "Read word2vec:   6%|▌         | 113228/2000000 [00:12<03:20, 9420.49it/s]\u001b[A\n",
            "Read word2vec:   6%|▌         | 114188/2000000 [00:13<04:12, 7463.88it/s]\u001b[A\n",
            "Read word2vec:   6%|▌         | 115178/2000000 [00:13<03:54, 8040.59it/s]\u001b[A\n",
            "Read word2vec:   6%|▌         | 116311/2000000 [00:13<03:32, 8870.57it/s]\u001b[A\n",
            "Read word2vec:   6%|▌         | 117701/2000000 [00:13<03:04, 10202.03it/s]\u001b[A\n",
            "Read word2vec:   6%|▌         | 119142/2000000 [00:13<02:45, 11354.28it/s]\u001b[A\n",
            "Read word2vec:   6%|▌         | 120330/2000000 [00:13<03:06, 10103.28it/s]\u001b[A\n",
            "Read word2vec:   6%|▌         | 121572/2000000 [00:13<02:55, 10707.16it/s]\u001b[A\n",
            "Read word2vec:   6%|▌         | 122921/2000000 [00:13<02:43, 11458.64it/s]\u001b[A\n",
            "Read word2vec:   6%|▌         | 124111/2000000 [00:14<02:48, 11111.94it/s]\u001b[A\n",
            "Read word2vec:   6%|▋         | 125360/2000000 [00:14<02:43, 11492.70it/s]\u001b[A\n",
            "Read word2vec:   6%|▋         | 126535/2000000 [00:14<03:31, 8850.59it/s] \u001b[A\n",
            "Read word2vec:   6%|▋         | 127527/2000000 [00:14<03:33, 8760.93it/s]\u001b[A\n",
            "Read word2vec:   6%|▋         | 128706/2000000 [00:14<03:16, 9503.76it/s]\u001b[A\n",
            "Read word2vec:   6%|▋         | 129948/2000000 [00:14<03:02, 10257.80it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 131185/2000000 [00:14<02:52, 10828.52it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 132407/2000000 [00:14<02:46, 11215.03it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 133645/2000000 [00:14<02:42, 11466.77it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 134853/2000000 [00:15<02:40, 11641.89it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 136208/2000000 [00:15<02:32, 12196.37it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 137443/2000000 [00:15<02:46, 11196.89it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 138640/2000000 [00:15<02:43, 11409.94it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 139801/2000000 [00:15<03:15, 9505.13it/s] \u001b[A\n",
            "Read word2vec:   7%|▋         | 140991/2000000 [00:15<03:03, 10107.07it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 142122/2000000 [00:15<02:58, 10424.34it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 143209/2000000 [00:15<03:02, 10180.96it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 144528/2000000 [00:15<02:48, 11002.17it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 145658/2000000 [00:16<03:10, 9742.16it/s] \u001b[A\n",
            "Read word2vec:   7%|▋         | 146676/2000000 [00:16<03:41, 8362.02it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 147570/2000000 [00:16<04:11, 7364.47it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 148360/2000000 [00:16<04:30, 6850.66it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 149081/2000000 [00:16<04:49, 6384.07it/s]\u001b[A\n",
            "Read word2vec:   7%|▋         | 149744/2000000 [00:16<05:28, 5628.05it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 150331/2000000 [00:17<05:29, 5612.35it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 151457/2000000 [00:17<04:25, 6973.67it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 152645/2000000 [00:17<03:44, 8230.05it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 153785/2000000 [00:17<03:23, 9078.43it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 154985/2000000 [00:17<03:06, 9885.79it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 156407/2000000 [00:17<02:45, 11113.07it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 157707/2000000 [00:17<02:38, 11652.25it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 159099/2000000 [00:17<02:29, 12311.88it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 160420/2000000 [00:17<02:26, 12574.52it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 161724/2000000 [00:17<02:24, 12711.31it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 163144/2000000 [00:18<02:19, 13152.38it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 164468/2000000 [00:18<02:22, 12856.98it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 165939/2000000 [00:18<02:16, 13399.09it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 167505/2000000 [00:18<02:10, 14065.80it/s]\u001b[A\n",
            "Read word2vec:   8%|▊         | 168961/2000000 [00:18<02:08, 14210.21it/s]\u001b[A\n",
            "Read word2vec:   9%|▊         | 170414/2000000 [00:18<02:07, 14305.19it/s]\u001b[A\n",
            "Read word2vec:   9%|▊         | 171848/2000000 [00:18<02:17, 13328.37it/s]\u001b[A\n",
            "Read word2vec:   9%|▊         | 173196/2000000 [00:18<02:22, 12776.41it/s]\u001b[A\n",
            "Read word2vec:   9%|▊         | 174488/2000000 [00:18<02:51, 10642.02it/s]\u001b[A\n",
            "Read word2vec:   9%|▉         | 175616/2000000 [00:19<03:15, 9354.67it/s] \u001b[A\n",
            "Read word2vec:   9%|▉         | 176615/2000000 [00:19<03:48, 7992.78it/s]\u001b[A\n",
            "Read word2vec:   9%|▉         | 177480/2000000 [00:19<03:48, 7975.57it/s]\u001b[A\n",
            "Read word2vec:   9%|▉         | 178938/2000000 [00:19<03:11, 9533.35it/s]\u001b[A\n",
            "Read word2vec:   9%|▉         | 180274/2000000 [00:19<02:53, 10497.84it/s]\u001b[A\n",
            "Read word2vec:   9%|▉         | 181428/2000000 [00:19<02:48, 10773.28it/s]\u001b[A\n",
            "Read word2vec:   9%|▉         | 182694/2000000 [00:19<02:40, 11290.40it/s]\u001b[A\n",
            "Read word2vec:   9%|▉         | 184001/2000000 [00:19<02:34, 11790.99it/s]\u001b[A\n",
            "Read word2vec:   9%|▉         | 185213/2000000 [00:19<02:33, 11791.38it/s]\u001b[A\n",
            "Read word2vec:   9%|▉         | 186712/2000000 [00:20<02:22, 12712.64it/s]\u001b[A\n",
            "Read word2vec:   9%|▉         | 188003/2000000 [00:20<02:24, 12512.83it/s]\u001b[A\n",
            "Read word2vec:   9%|▉         | 189269/2000000 [00:20<02:52, 10500.86it/s]\u001b[A\n",
            "Read word2vec:  10%|▉         | 190382/2000000 [00:20<02:57, 10195.85it/s]\u001b[A\n",
            "Read word2vec:  10%|▉         | 191752/2000000 [00:20<02:42, 11104.96it/s]\u001b[A\n",
            "Read word2vec:  10%|▉         | 192917/2000000 [00:20<02:40, 11251.15it/s]\u001b[A\n",
            "Read word2vec:  10%|▉         | 194429/2000000 [00:20<02:26, 12328.79it/s]\u001b[A\n",
            "Read word2vec:  10%|▉         | 195693/2000000 [00:20<02:27, 12236.74it/s]\u001b[A\n",
            "Read word2vec:  10%|▉         | 196938/2000000 [00:21<02:40, 11246.18it/s]\u001b[A\n",
            "Read word2vec:  10%|▉         | 198566/2000000 [00:21<02:22, 12597.91it/s]\u001b[A\n",
            "Read word2vec:  10%|█         | 200018/2000000 [00:21<02:17, 13133.54it/s]\u001b[A\n",
            "Read word2vec:  10%|█         | 201649/2000000 [00:21<02:08, 14038.27it/s]\u001b[A\n",
            "Read word2vec:  10%|█         | 203077/2000000 [00:21<02:15, 13308.49it/s]\u001b[A\n",
            "Read word2vec:  10%|█         | 204431/2000000 [00:21<02:20, 12739.41it/s]\u001b[A\n",
            "Read word2vec:  10%|█         | 205835/2000000 [00:21<02:16, 13098.80it/s]\u001b[A\n",
            "Read word2vec:  10%|█         | 207384/2000000 [00:21<02:10, 13775.10it/s]\u001b[A\n",
            "Read word2vec:  10%|█         | 208777/2000000 [00:21<02:20, 12747.01it/s]\u001b[A\n",
            "Read word2vec:  11%|█         | 210076/2000000 [00:21<02:22, 12599.36it/s]\u001b[A\n",
            "Read word2vec:  11%|█         | 211352/2000000 [00:22<02:23, 12496.64it/s]\u001b[A\n",
            "Read word2vec:  11%|█         | 212657/2000000 [00:22<02:24, 12340.39it/s]\u001b[A\n",
            "Read word2vec:  11%|█         | 213899/2000000 [00:22<02:44, 10860.60it/s]\u001b[A\n",
            "Read word2vec:  11%|█         | 215019/2000000 [00:22<02:59, 9923.01it/s] \u001b[A\n",
            "Read word2vec:  11%|█         | 216044/2000000 [00:22<03:08, 9471.93it/s]\u001b[A\n",
            "Read word2vec:  11%|█         | 217066/2000000 [00:22<03:06, 9580.36it/s]\u001b[A\n",
            "Read word2vec:  11%|█         | 218041/2000000 [00:22<03:15, 9133.84it/s]\u001b[A\n",
            "Read word2vec:  11%|█         | 220254/2000000 [00:22<02:21, 12569.43it/s]\u001b[A\n",
            "Read word2vec:  11%|█         | 223189/2000000 [00:23<01:43, 17170.09it/s]\u001b[A\n",
            "Read word2vec:  11%|█▏        | 226278/2000000 [00:23<01:24, 21030.71it/s]\u001b[A\n",
            "Read word2vec:  11%|█▏        | 228836/2000000 [00:23<01:19, 22330.84it/s]\u001b[A\n",
            "Read word2vec:  12%|█▏        | 232034/2000000 [00:23<01:10, 25133.79it/s]\u001b[A\n",
            "Read word2vec:  12%|█▏        | 235014/2000000 [00:23<01:06, 26499.17it/s]\u001b[A\n",
            "Read word2vec:  12%|█▏        | 238204/2000000 [00:23<01:02, 28092.85it/s]\u001b[A\n",
            "Read word2vec:  12%|█▏        | 241534/2000000 [00:23<00:59, 29635.52it/s]\u001b[A\n",
            "Read word2vec:  12%|█▏        | 244541/2000000 [00:23<00:58, 29760.10it/s]\u001b[A\n",
            "Read word2vec:  12%|█▏        | 247819/2000000 [00:23<00:57, 30660.24it/s]\u001b[A\n",
            "Read word2vec:  13%|█▎        | 251080/2000000 [00:23<00:55, 31237.17it/s]\u001b[A\n",
            "Read word2vec:  13%|█▎        | 254213/2000000 [00:24<01:00, 28753.91it/s]\u001b[A\n",
            "Read word2vec:  13%|█▎        | 257263/2000000 [00:24<00:59, 29246.43it/s]\u001b[A\n",
            "Read word2vec:  13%|█▎        | 260223/2000000 [00:24<00:59, 29232.88it/s]\u001b[A\n",
            "Read word2vec:  13%|█▎        | 263401/2000000 [00:24<00:57, 29971.83it/s]\u001b[A\n",
            "Read word2vec:  13%|█▎        | 266425/2000000 [00:24<00:57, 30049.27it/s]\u001b[A\n",
            "Read word2vec:  13%|█▎        | 269656/2000000 [00:24<00:56, 30714.01it/s]\u001b[A\n",
            "Read word2vec:  14%|█▎        | 272739/2000000 [00:24<00:56, 30605.26it/s]\u001b[A\n",
            "Read word2vec:  14%|█▍        | 275827/2000000 [00:24<00:56, 30680.62it/s]\u001b[A\n",
            "Read word2vec:  14%|█▍        | 278907/2000000 [00:24<00:56, 30715.80it/s]\u001b[A\n",
            "Read word2vec:  14%|█▍        | 281983/2000000 [00:24<00:57, 30121.19it/s]\u001b[A\n",
            "Read word2vec:  14%|█▍        | 285001/2000000 [00:25<00:57, 29835.59it/s]\u001b[A\n",
            "Read word2vec:  14%|█▍        | 288301/2000000 [00:25<00:55, 30765.36it/s]\u001b[A\n",
            "Read word2vec:  15%|█▍        | 291382/2000000 [00:25<00:57, 29887.56it/s]\u001b[A\n",
            "Read word2vec:  15%|█▍        | 294401/2000000 [00:25<00:56, 29969.77it/s]\u001b[A\n",
            "Read word2vec:  15%|█▍        | 297798/2000000 [00:25<00:54, 31142.37it/s]\u001b[A\n",
            "Read word2vec:  15%|█▌        | 301050/2000000 [00:25<00:53, 31543.97it/s]\u001b[A\n",
            "Read word2vec:  15%|█▌        | 304210/2000000 [00:25<00:53, 31463.83it/s]\u001b[A\n",
            "Read word2vec:  15%|█▌        | 307649/2000000 [00:25<00:52, 32331.48it/s]\u001b[A\n",
            "Read word2vec:  16%|█▌        | 311080/2000000 [00:25<00:51, 32919.63it/s]\u001b[A\n",
            "Read word2vec:  16%|█▌        | 314375/2000000 [00:26<00:53, 31736.96it/s]\u001b[A\n",
            "Read word2vec:  16%|█▌        | 317561/2000000 [00:26<00:52, 31769.24it/s]\u001b[A\n",
            "Read word2vec:  16%|█▌        | 320796/2000000 [00:26<00:52, 31939.79it/s]\u001b[A\n",
            "Read word2vec:  16%|█▌        | 323996/2000000 [00:26<00:54, 30619.19it/s]\u001b[A\n",
            "Read word2vec:  16%|█▋        | 327293/2000000 [00:26<00:53, 31294.53it/s]\u001b[A\n",
            "Read word2vec:  17%|█▋        | 330637/2000000 [00:26<00:52, 31916.32it/s]\u001b[A\n",
            "Read word2vec:  17%|█▋        | 333873/2000000 [00:26<00:51, 32043.85it/s]\u001b[A\n",
            "Read word2vec:  17%|█▋        | 337376/2000000 [00:26<00:50, 32924.35it/s]\u001b[A\n",
            "Read word2vec:  17%|█▋        | 340676/2000000 [00:26<00:50, 32674.91it/s]\u001b[A\n",
            "Read word2vec:  17%|█▋        | 343949/2000000 [00:26<00:52, 31639.28it/s]\u001b[A\n",
            "Read word2vec:  17%|█▋        | 347270/2000000 [00:27<00:51, 32087.84it/s]\u001b[A\n",
            "Read word2vec:  18%|█▊        | 350826/2000000 [00:27<00:49, 33105.11it/s]\u001b[A\n",
            "Read word2vec:  18%|█▊        | 354145/2000000 [00:27<00:49, 32944.53it/s]\u001b[A\n",
            "Read word2vec:  18%|█▊        | 357446/2000000 [00:27<00:51, 32160.91it/s]\u001b[A\n",
            "Read word2vec:  18%|█▊        | 360880/2000000 [00:27<00:49, 32796.22it/s]\u001b[A\n",
            "Read word2vec:  18%|█▊        | 364170/2000000 [00:27<00:49, 32824.59it/s]\u001b[A\n",
            "Read word2vec:  18%|█▊        | 367677/2000000 [00:27<00:48, 33487.72it/s]\u001b[A\n",
            "Read word2vec:  19%|█▊        | 371037/2000000 [00:27<00:48, 33516.88it/s]\u001b[A\n",
            "Read word2vec:  19%|█▊        | 374392/2000000 [00:27<00:48, 33388.68it/s]\u001b[A\n",
            "Read word2vec:  19%|█▉        | 377767/2000000 [00:27<00:48, 33495.08it/s]\u001b[A\n",
            "Read word2vec:  19%|█▉        | 381127/2000000 [00:28<00:48, 33524.78it/s]\u001b[A\n",
            "Read word2vec:  19%|█▉        | 384638/2000000 [00:28<00:47, 33995.37it/s]\u001b[A\n",
            "Read word2vec:  19%|█▉        | 388039/2000000 [00:28<00:49, 32675.31it/s]\u001b[A\n",
            "Read word2vec:  20%|█▉        | 391318/2000000 [00:28<00:50, 31834.27it/s]\u001b[A\n",
            "Read word2vec:  20%|█▉        | 394513/2000000 [00:28<00:53, 29946.74it/s]\u001b[A\n",
            "Read word2vec:  20%|█▉        | 397768/2000000 [00:28<00:52, 30670.83it/s]\u001b[A\n",
            "Read word2vec:  20%|██        | 400859/2000000 [00:28<00:53, 30039.48it/s]\u001b[A\n",
            "Read word2vec:  20%|██        | 404203/2000000 [00:28<00:51, 31006.00it/s]\u001b[A\n",
            "Read word2vec:  20%|██        | 407514/2000000 [00:28<00:50, 31613.84it/s]\u001b[A\n",
            "Read word2vec:  21%|██        | 410690/2000000 [00:29<00:51, 31089.09it/s]\u001b[A\n",
            "Read word2vec:  21%|██        | 413846/2000000 [00:29<00:50, 31224.66it/s]\u001b[A\n",
            "Read word2vec:  21%|██        | 416977/2000000 [00:29<00:51, 30981.03it/s]\u001b[A\n",
            "Read word2vec:  21%|██        | 420107/2000000 [00:29<00:50, 31070.49it/s]\u001b[A\n",
            "Read word2vec:  21%|██        | 423285/2000000 [00:29<00:50, 31279.59it/s]\u001b[A\n",
            "Read word2vec:  21%|██▏       | 426507/2000000 [00:29<00:49, 31557.29it/s]\u001b[A\n",
            "Read word2vec:  21%|██▏       | 429786/2000000 [00:29<00:49, 31924.23it/s]\u001b[A\n",
            "Read word2vec:  22%|██▏       | 433184/2000000 [00:29<00:48, 32537.56it/s]\u001b[A\n",
            "Read word2vec:  22%|██▏       | 436642/2000000 [00:29<00:47, 33141.54it/s]\u001b[A\n",
            "Read word2vec:  22%|██▏       | 439958/2000000 [00:29<00:48, 32335.84it/s]\u001b[A\n",
            "Read word2vec:  22%|██▏       | 443380/2000000 [00:30<00:47, 32889.19it/s]\u001b[A\n",
            "Read word2vec:  22%|██▏       | 446843/2000000 [00:30<00:46, 33403.40it/s]\u001b[A\n",
            "Read word2vec:  23%|██▎       | 450188/2000000 [00:30<00:47, 32654.14it/s]\u001b[A\n",
            "Read word2vec:  23%|██▎       | 453607/2000000 [00:30<00:46, 33103.12it/s]\u001b[A\n",
            "Read word2vec:  23%|██▎       | 456923/2000000 [00:30<00:47, 32440.62it/s]\u001b[A\n",
            "Read word2vec:  23%|██▎       | 460242/2000000 [00:30<00:47, 32658.95it/s]\u001b[A\n",
            "Read word2vec:  23%|██▎       | 463619/2000000 [00:30<00:46, 32985.44it/s]\u001b[A\n",
            "Read word2vec:  23%|██▎       | 466922/2000000 [00:30<00:46, 32884.30it/s]\u001b[A\n",
            "Read word2vec:  24%|██▎       | 470214/2000000 [00:30<00:48, 31331.84it/s]\u001b[A\n",
            "Read word2vec:  24%|██▎       | 473447/2000000 [00:30<00:48, 31616.20it/s]\u001b[A\n",
            "Read word2vec:  24%|██▍       | 476797/2000000 [00:31<00:47, 32164.24it/s]\u001b[A\n",
            "Read word2vec:  24%|██▍       | 480041/2000000 [00:31<00:47, 32242.61it/s]\u001b[A\n",
            "Read word2vec:  24%|██▍       | 483404/2000000 [00:31<00:46, 32652.40it/s]\u001b[A\n",
            "Read word2vec:  24%|██▍       | 486757/2000000 [00:31<00:45, 32910.81it/s]\u001b[A\n",
            "Read word2vec:  25%|██▍       | 490053/2000000 [00:31<00:46, 32460.15it/s]\u001b[A\n",
            "Read word2vec:  25%|██▍       | 493304/2000000 [00:31<00:46, 32308.60it/s]\u001b[A\n",
            "Read word2vec:  25%|██▍       | 496807/2000000 [00:31<00:45, 33113.40it/s]\u001b[A\n",
            "Read word2vec:  25%|██▌       | 500122/2000000 [00:31<00:46, 32348.95it/s]\u001b[A\n",
            "Read word2vec:  25%|██▌       | 503363/2000000 [00:31<00:46, 32020.79it/s]\u001b[A\n",
            "Read word2vec:  25%|██▌       | 506628/2000000 [00:31<00:46, 32204.86it/s]\u001b[A\n",
            "Read word2vec:  25%|██▌       | 509896/2000000 [00:32<00:46, 32344.00it/s]\u001b[A\n",
            "Read word2vec:  26%|██▌       | 513232/2000000 [00:32<00:45, 32645.14it/s]\u001b[A\n",
            "Read word2vec:  26%|██▌       | 516499/2000000 [00:32<00:45, 32606.80it/s]\u001b[A\n",
            "Read word2vec:  26%|██▌       | 519803/2000000 [00:32<00:45, 32733.65it/s]\u001b[A\n",
            "Read word2vec:  26%|██▌       | 523103/2000000 [00:32<00:45, 32812.45it/s]\u001b[A\n",
            "Read word2vec:  26%|██▋       | 526508/2000000 [00:32<00:44, 33182.03it/s]\u001b[A\n",
            "Read word2vec:  26%|██▋       | 529827/2000000 [00:32<00:44, 33078.45it/s]\u001b[A\n",
            "Read word2vec:  27%|██▋       | 533169/2000000 [00:32<00:44, 33179.72it/s]\u001b[A\n",
            "Read word2vec:  27%|██▋       | 536747/2000000 [00:32<00:43, 33955.72it/s]\u001b[A\n",
            "Read word2vec:  27%|██▋       | 540144/2000000 [00:32<00:44, 33084.56it/s]\u001b[A\n",
            "Read word2vec:  27%|██▋       | 543515/2000000 [00:33<00:43, 33261.12it/s]\u001b[A\n",
            "Read word2vec:  27%|██▋       | 546947/2000000 [00:33<00:43, 33570.18it/s]\u001b[A\n",
            "Read word2vec:  28%|██▊       | 550308/2000000 [00:33<00:44, 32879.37it/s]\u001b[A\n",
            "Read word2vec:  28%|██▊       | 553644/2000000 [00:33<00:43, 33020.38it/s]\u001b[A\n",
            "Read word2vec:  28%|██▊       | 556950/2000000 [00:33<00:44, 32421.09it/s]\u001b[A\n",
            "Read word2vec:  28%|██▊       | 560197/2000000 [00:33<00:44, 32117.43it/s]\u001b[A\n",
            "Read word2vec:  28%|██▊       | 563681/2000000 [00:33<00:43, 32913.85it/s]\u001b[A\n",
            "Read word2vec:  28%|██▊       | 566977/2000000 [00:33<00:43, 32916.85it/s]\u001b[A\n",
            "Read word2vec:  29%|██▊       | 570272/2000000 [00:33<00:44, 32290.96it/s]\u001b[A\n",
            "Read word2vec:  29%|██▊       | 573800/2000000 [00:34<00:42, 33167.62it/s]\u001b[A\n",
            "Read word2vec:  29%|██▉       | 577122/2000000 [00:34<00:43, 32874.66it/s]\u001b[A\n",
            "Read word2vec:  29%|██▉       | 580538/2000000 [00:34<00:42, 33252.37it/s]\u001b[A\n",
            "Read word2vec:  29%|██▉       | 584032/2000000 [00:34<00:41, 33752.34it/s]\u001b[A\n",
            "Read word2vec:  29%|██▉       | 587411/2000000 [00:34<00:41, 33661.53it/s]\u001b[A\n",
            "Read word2vec:  30%|██▉       | 590780/2000000 [00:34<00:42, 32828.80it/s]\u001b[A\n",
            "Read word2vec:  30%|██▉       | 594272/2000000 [00:34<00:42, 33441.03it/s]\u001b[A\n",
            "Read word2vec:  30%|██▉       | 597639/2000000 [00:34<00:41, 33506.48it/s]\u001b[A\n",
            "Read word2vec:  30%|███       | 600994/2000000 [00:34<00:42, 33072.38it/s]\u001b[A\n",
            "Read word2vec:  30%|███       | 604333/2000000 [00:34<00:42, 33164.91it/s]\u001b[A\n",
            "Read word2vec:  30%|███       | 607864/2000000 [00:35<00:41, 33799.49it/s]\u001b[A\n",
            "Read word2vec:  31%|███       | 611247/2000000 [00:35<00:41, 33709.07it/s]\u001b[A\n",
            "Read word2vec:  31%|███       | 614686/2000000 [00:35<00:40, 33901.07it/s]\u001b[A\n",
            "Read word2vec:  31%|███       | 618078/2000000 [00:35<00:41, 33482.16it/s]\u001b[A\n",
            "Read word2vec:  31%|███       | 621429/2000000 [00:35<00:41, 33117.26it/s]\u001b[A\n",
            "Read word2vec:  31%|███       | 624743/2000000 [00:35<00:41, 32910.72it/s]\u001b[A\n",
            "Read word2vec:  31%|███▏      | 628114/2000000 [00:35<00:41, 33145.31it/s]\u001b[A\n",
            "Read word2vec:  32%|███▏      | 631462/2000000 [00:35<00:41, 33243.37it/s]\u001b[A\n",
            "Read word2vec:  32%|███▏      | 634972/2000000 [00:35<00:40, 33786.32it/s]\u001b[A\n",
            "Read word2vec:  32%|███▏      | 638352/2000000 [00:35<00:40, 33409.66it/s]\u001b[A\n",
            "Read word2vec:  32%|███▏      | 641695/2000000 [00:36<00:41, 32855.08it/s]\u001b[A\n",
            "Read word2vec:  32%|███▏      | 645217/2000000 [00:36<00:40, 33548.00it/s]\u001b[A\n",
            "Read word2vec:  32%|███▏      | 648628/2000000 [00:36<00:40, 33713.58it/s]\u001b[A\n",
            "Read word2vec:  33%|███▎      | 652002/2000000 [00:36<00:40, 32994.79it/s]\u001b[A\n",
            "Read word2vec:  33%|███▎      | 655468/2000000 [00:36<00:40, 33483.08it/s]\u001b[A\n",
            "Read word2vec:  33%|███▎      | 658821/2000000 [00:36<00:40, 32796.83it/s]\u001b[A\n",
            "Read word2vec:  33%|███▎      | 662325/2000000 [00:36<00:39, 33445.72it/s]\u001b[A\n",
            "Read word2vec:  33%|███▎      | 665789/2000000 [00:36<00:39, 33796.44it/s]\u001b[A\n",
            "Read word2vec:  33%|███▎      | 669395/2000000 [00:36<00:38, 34464.54it/s]\u001b[A\n",
            "Read word2vec:  34%|███▎      | 672846/2000000 [00:36<00:39, 33947.26it/s]\u001b[A\n",
            "Read word2vec:  34%|███▍      | 676245/2000000 [00:37<00:39, 33271.72it/s]\u001b[A\n",
            "Read word2vec:  34%|███▍      | 679578/2000000 [00:37<00:39, 33229.19it/s]\u001b[A\n",
            "Read word2vec:  34%|███▍      | 682970/2000000 [00:37<00:39, 33432.16it/s]\u001b[A\n",
            "Read word2vec:  34%|███▍      | 686316/2000000 [00:37<00:39, 33412.03it/s]\u001b[A\n",
            "Read word2vec:  34%|███▍      | 689749/2000000 [00:37<00:38, 33683.00it/s]\u001b[A\n",
            "Read word2vec:  35%|███▍      | 693119/2000000 [00:37<00:39, 33172.35it/s]\u001b[A\n",
            "Read word2vec:  35%|███▍      | 696490/2000000 [00:37<00:39, 33329.38it/s]\u001b[A\n",
            "Read word2vec:  35%|███▍      | 699987/2000000 [00:37<00:38, 33815.04it/s]\u001b[A\n",
            "Read word2vec:  35%|███▌      | 703371/2000000 [00:37<00:38, 33260.95it/s]\u001b[A\n",
            "Read word2vec:  35%|███▌      | 706757/2000000 [00:37<00:38, 33437.40it/s]\u001b[A\n",
            "Read word2vec:  36%|███▌      | 710117/2000000 [00:38<00:38, 33485.17it/s]\u001b[A\n",
            "Read word2vec:  36%|███▌      | 713519/2000000 [00:38<00:38, 33642.60it/s]\u001b[A\n",
            "Read word2vec:  36%|███▌      | 717041/2000000 [00:38<00:37, 34111.53it/s]\u001b[A\n",
            "Read word2vec:  36%|███▌      | 720454/2000000 [00:38<00:37, 33773.94it/s]\u001b[A\n",
            "Read word2vec:  36%|███▌      | 723972/2000000 [00:38<00:37, 34190.09it/s]\u001b[A\n",
            "Read word2vec:  36%|███▋      | 727393/2000000 [00:38<00:38, 33213.03it/s]\u001b[A\n",
            "Read word2vec:  37%|███▋      | 730781/2000000 [00:38<00:37, 33405.55it/s]\u001b[A\n",
            "Read word2vec:  37%|███▋      | 734127/2000000 [00:38<00:38, 32577.59it/s]\u001b[A\n",
            "Read word2vec:  37%|███▋      | 737633/2000000 [00:38<00:37, 33298.91it/s]\u001b[A\n",
            "Read word2vec:  37%|███▋      | 740970/2000000 [00:39<00:37, 33142.76it/s]\u001b[A\n",
            "Read word2vec:  37%|███▋      | 744333/2000000 [00:39<00:37, 33272.96it/s]\u001b[A\n",
            "Read word2vec:  37%|███▋      | 747777/2000000 [00:39<00:37, 33616.28it/s]\u001b[A\n",
            "Read word2vec:  38%|███▊      | 751230/2000000 [00:39<00:36, 33887.03it/s]\u001b[A\n",
            "Read word2vec:  38%|███▊      | 754702/2000000 [00:39<00:36, 34134.21it/s]\u001b[A\n",
            "Read word2vec:  38%|███▊      | 758118/2000000 [00:39<00:36, 33889.55it/s]\u001b[A\n",
            "Read word2vec:  38%|███▊      | 761509/2000000 [00:39<00:36, 33557.39it/s]\u001b[A\n",
            "Read word2vec:  38%|███▊      | 764867/2000000 [00:39<00:36, 33402.53it/s]\u001b[A\n",
            "Read word2vec:  38%|███▊      | 768392/2000000 [00:39<00:36, 33949.45it/s]\u001b[A\n",
            "Read word2vec:  39%|███▊      | 771897/2000000 [00:39<00:35, 34275.30it/s]\u001b[A\n",
            "Read word2vec:  39%|███▉      | 775326/2000000 [00:40<00:36, 33574.62it/s]\u001b[A\n",
            "Read word2vec:  39%|███▉      | 778688/2000000 [00:40<00:36, 33134.45it/s]\u001b[A\n",
            "Read word2vec:  39%|███▉      | 782005/2000000 [00:40<00:37, 32581.51it/s]\u001b[A\n",
            "Read word2vec:  39%|███▉      | 785304/2000000 [00:40<00:37, 32697.52it/s]\u001b[A\n",
            "Read word2vec:  39%|███▉      | 788773/2000000 [00:40<00:36, 33282.50it/s]\u001b[A\n",
            "Read word2vec:  40%|███▉      | 792290/2000000 [00:40<00:35, 33840.75it/s]\u001b[A\n",
            "Read word2vec:  40%|███▉      | 795677/2000000 [00:40<00:36, 32755.46it/s]\u001b[A\n",
            "Read word2vec:  40%|███▉      | 799207/2000000 [00:40<00:35, 33495.35it/s]\u001b[A\n",
            "Read word2vec:  40%|████      | 802565/2000000 [00:40<00:36, 33018.63it/s]\u001b[A\n",
            "Read word2vec:  40%|████      | 805874/2000000 [00:40<00:36, 32590.67it/s]\u001b[A\n",
            "Read word2vec:  40%|████      | 809332/2000000 [00:41<00:35, 33162.73it/s]\u001b[A\n",
            "Read word2vec:  41%|████      | 812748/2000000 [00:41<00:35, 33455.77it/s]\u001b[A\n",
            "Read word2vec:  41%|████      | 816098/2000000 [00:41<00:36, 32857.02it/s]\u001b[A\n",
            "Read word2vec:  41%|████      | 819795/2000000 [00:41<00:34, 34060.10it/s]\u001b[A\n",
            "Read word2vec:  41%|████      | 823326/2000000 [00:41<00:34, 34426.65it/s]\u001b[A\n",
            "Read word2vec:  41%|████▏     | 826946/2000000 [00:41<00:33, 34951.42it/s]\u001b[A\n",
            "Read word2vec:  42%|████▏     | 830446/2000000 [00:41<00:34, 33840.16it/s]\u001b[A\n",
            "Read word2vec:  42%|████▏     | 833840/2000000 [00:41<00:34, 33677.07it/s]\u001b[A\n",
            "Read word2vec:  42%|████▏     | 837250/2000000 [00:41<00:34, 33786.83it/s]\u001b[A\n",
            "Read word2vec:  42%|████▏     | 840866/2000000 [00:41<00:33, 34485.52it/s]\u001b[A\n",
            "Read word2vec:  42%|████▏     | 844320/2000000 [00:42<00:33, 34185.01it/s]\u001b[A\n",
            "Read word2vec:  42%|████▏     | 847871/2000000 [00:42<00:33, 34576.48it/s]\u001b[A\n",
            "Read word2vec:  43%|████▎     | 851332/2000000 [00:42<00:33, 34553.94it/s]\u001b[A\n",
            "Read word2vec:  43%|████▎     | 854894/2000000 [00:42<00:32, 34869.70it/s]\u001b[A\n",
            "Read word2vec:  43%|████▎     | 858383/2000000 [00:42<00:33, 34212.27it/s]\u001b[A\n",
            "Read word2vec:  43%|████▎     | 862094/2000000 [00:42<00:32, 35056.98it/s]\u001b[A\n",
            "Read word2vec:  43%|████▎     | 865604/2000000 [00:42<00:33, 34125.63it/s]\u001b[A\n",
            "Read word2vec:  43%|████▎     | 869024/2000000 [00:42<00:33, 33355.57it/s]\u001b[A\n",
            "Read word2vec:  44%|████▎     | 872367/2000000 [00:42<00:33, 33201.30it/s]\u001b[A\n",
            "Read word2vec:  44%|████▍     | 875692/2000000 [00:43<00:33, 33205.26it/s]\u001b[A\n",
            "Read word2vec:  44%|████▍     | 879148/2000000 [00:43<00:33, 33602.78it/s]\u001b[A\n",
            "Read word2vec:  44%|████▍     | 882645/2000000 [00:43<00:32, 34004.87it/s]\u001b[A\n",
            "Read word2vec:  44%|████▍     | 886049/2000000 [00:43<00:32, 33910.50it/s]\u001b[A\n",
            "Read word2vec:  44%|████▍     | 889588/2000000 [00:43<00:32, 34348.00it/s]\u001b[A\n",
            "Read word2vec:  45%|████▍     | 893034/2000000 [00:43<00:32, 34379.82it/s]\u001b[A\n",
            "Read word2vec:  45%|████▍     | 896739/2000000 [00:43<00:31, 35175.62it/s]\u001b[A\n",
            "Read word2vec:  45%|████▌     | 900258/2000000 [00:43<00:32, 34340.81it/s]\u001b[A\n",
            "Read word2vec:  45%|████▌     | 903835/2000000 [00:43<00:31, 34761.36it/s]\u001b[A\n",
            "Read word2vec:  45%|████▌     | 907451/2000000 [00:43<00:31, 35174.10it/s]\u001b[A\n",
            "Read word2vec:  46%|████▌     | 910973/2000000 [00:44<00:31, 34505.31it/s]\u001b[A\n",
            "Read word2vec:  46%|████▌     | 914429/2000000 [00:44<00:31, 34118.26it/s]\u001b[A\n",
            "Read word2vec:  46%|████▌     | 917952/2000000 [00:44<00:31, 34444.08it/s]\u001b[A\n",
            "Read word2vec:  46%|████▌     | 921579/2000000 [00:44<00:30, 34981.69it/s]\u001b[A\n",
            "Read word2vec:  46%|████▋     | 925165/2000000 [00:44<00:30, 35241.24it/s]\u001b[A\n",
            "Read word2vec:  46%|████▋     | 928692/2000000 [00:44<00:30, 35018.94it/s]\u001b[A\n",
            "Read word2vec:  47%|████▋     | 932269/2000000 [00:44<00:30, 35241.85it/s]\u001b[A\n",
            "Read word2vec:  47%|████▋     | 935795/2000000 [00:44<00:32, 32308.99it/s]\u001b[A\n",
            "Read word2vec:  47%|████▋     | 939176/2000000 [00:44<00:32, 32728.49it/s]\u001b[A\n",
            "Read word2vec:  47%|████▋     | 942486/2000000 [00:44<00:32, 32823.94it/s]\u001b[A\n",
            "Read word2vec:  47%|████▋     | 946122/2000000 [00:45<00:31, 33848.92it/s]\u001b[A\n",
            "Read word2vec:  47%|████▋     | 949806/2000000 [00:45<00:30, 34718.60it/s]\u001b[A\n",
            "Read word2vec:  48%|████▊     | 953295/2000000 [00:45<00:30, 34507.48it/s]\u001b[A\n",
            "Read word2vec:  48%|████▊     | 956816/2000000 [00:45<00:30, 34713.29it/s]\u001b[A\n",
            "Read word2vec:  48%|████▊     | 960398/2000000 [00:45<00:29, 35040.18it/s]\u001b[A\n",
            "Read word2vec:  48%|████▊     | 963918/2000000 [00:45<00:29, 35087.19it/s]\u001b[A\n",
            "Read word2vec:  48%|████▊     | 967432/2000000 [00:45<00:30, 34272.15it/s]\u001b[A\n",
            "Read word2vec:  49%|████▊     | 970867/2000000 [00:45<00:30, 33989.44it/s]\u001b[A\n",
            "Read word2vec:  49%|████▊     | 974271/2000000 [00:45<00:30, 33614.84it/s]\u001b[A\n",
            "Read word2vec:  49%|████▉     | 977637/2000000 [00:45<00:30, 33433.57it/s]\u001b[A\n",
            "Read word2vec:  49%|████▉     | 981236/2000000 [00:46<00:29, 34184.75it/s]\u001b[A\n",
            "Read word2vec:  49%|████▉     | 984812/2000000 [00:46<00:29, 34650.58it/s]\u001b[A\n",
            "Read word2vec:  49%|████▉     | 988403/2000000 [00:46<00:28, 35023.98it/s]\u001b[A\n",
            "Read word2vec:  50%|████▉     | 991908/2000000 [00:46<00:28, 34832.65it/s]\u001b[A\n",
            "Read word2vec:  50%|████▉     | 995524/2000000 [00:46<00:28, 35203.51it/s]\u001b[A\n",
            "Read word2vec:  50%|████▉     | 999046/2000000 [00:46<00:28, 35190.18it/s]\u001b[A\n",
            "Read word2vec:  50%|█████     | 1002755/2000000 [00:46<00:27, 35755.63it/s]\u001b[A\n",
            "Read word2vec:  50%|█████     | 1006332/2000000 [00:46<00:28, 34276.45it/s]\u001b[A\n",
            "Read word2vec:  51%|█████     | 1010037/2000000 [00:46<00:28, 35081.30it/s]\u001b[A\n",
            "Read word2vec:  51%|█████     | 1013559/2000000 [00:46<00:28, 35120.02it/s]\u001b[A\n",
            "Read word2vec:  51%|█████     | 1017140/2000000 [00:47<00:27, 35322.83it/s]\u001b[A\n",
            "Read word2vec:  51%|█████     | 1020679/2000000 [00:47<00:27, 35085.08it/s]\u001b[A\n",
            "Read word2vec:  51%|█████     | 1024193/2000000 [00:47<00:27, 34904.95it/s]\u001b[A\n",
            "Read word2vec:  51%|█████▏    | 1027851/2000000 [00:47<00:27, 35400.24it/s]\u001b[A\n",
            "Read word2vec:  52%|█████▏    | 1031394/2000000 [00:47<00:27, 34721.54it/s]\u001b[A\n",
            "Read word2vec:  52%|█████▏    | 1034987/2000000 [00:47<00:27, 35071.83it/s]\u001b[A\n",
            "Read word2vec:  52%|█████▏    | 1038511/2000000 [00:47<00:27, 35116.40it/s]\u001b[A\n",
            "Read word2vec:  52%|█████▏    | 1042026/2000000 [00:47<00:28, 34075.95it/s]\u001b[A\n",
            "Read word2vec:  52%|█████▏    | 1045442/2000000 [00:47<00:28, 33399.03it/s]\u001b[A\n",
            "Read word2vec:  52%|█████▏    | 1048789/2000000 [00:48<00:29, 31929.78it/s]\u001b[A\n",
            "Read word2vec:  53%|█████▎    | 1051997/2000000 [00:48<00:30, 31096.06it/s]\u001b[A\n",
            "Read word2vec:  53%|█████▎    | 1055262/2000000 [00:48<00:29, 31533.47it/s]\u001b[A\n",
            "Read word2vec:  53%|█████▎    | 1058597/2000000 [00:48<00:29, 32055.28it/s]\u001b[A\n",
            "Read word2vec:  53%|█████▎    | 1062022/2000000 [00:48<00:28, 32693.24it/s]\u001b[A\n",
            "Read word2vec:  53%|█████▎    | 1065479/2000000 [00:48<00:28, 33243.75it/s]\u001b[A\n",
            "Read word2vec:  53%|█████▎    | 1068946/2000000 [00:48<00:27, 33662.76it/s]\u001b[A\n",
            "Read word2vec:  54%|█████▎    | 1072318/2000000 [00:48<00:27, 33295.99it/s]\u001b[A\n",
            "Read word2vec:  54%|█████▍    | 1075653/2000000 [00:48<00:27, 33260.60it/s]\u001b[A\n",
            "Read word2vec:  54%|█████▍    | 1078983/2000000 [00:48<00:28, 32823.87it/s]\u001b[A\n",
            "Read word2vec:  54%|█████▍    | 1082385/2000000 [00:49<00:27, 33174.62it/s]\u001b[A\n",
            "Read word2vec:  54%|█████▍    | 1085727/2000000 [00:49<00:27, 33246.31it/s]\u001b[A\n",
            "Read word2vec:  54%|█████▍    | 1089085/2000000 [00:49<00:27, 33343.02it/s]\u001b[A\n",
            "Read word2vec:  55%|█████▍    | 1092614/2000000 [00:49<00:26, 33921.67it/s]\u001b[A\n",
            "Read word2vec:  55%|█████▍    | 1096237/2000000 [00:49<00:26, 34609.65it/s]\u001b[A\n",
            "Read word2vec:  55%|█████▍    | 1099794/2000000 [00:49<00:25, 34896.12it/s]\u001b[A\n",
            "Read word2vec:  55%|█████▌    | 1103377/2000000 [00:49<00:25, 35174.85it/s]\u001b[A\n",
            "Read word2vec:  55%|█████▌    | 1106896/2000000 [00:49<00:25, 34956.37it/s]\u001b[A\n",
            "Read word2vec:  56%|█████▌    | 1110393/2000000 [00:49<00:25, 34381.80it/s]\u001b[A\n",
            "Read word2vec:  56%|█████▌    | 1113915/2000000 [00:49<00:25, 34626.76it/s]\u001b[A\n",
            "Read word2vec:  56%|█████▌    | 1117506/2000000 [00:50<00:25, 35004.80it/s]\u001b[A\n",
            "Read word2vec:  56%|█████▌    | 1121009/2000000 [00:50<00:25, 34233.96it/s]\u001b[A\n",
            "Read word2vec:  56%|█████▌    | 1124454/2000000 [00:50<00:25, 34296.77it/s]\u001b[A\n",
            "Read word2vec:  56%|█████▋    | 1127958/2000000 [00:50<00:25, 34514.69it/s]\u001b[A\n",
            "Read word2vec:  57%|█████▋    | 1131495/2000000 [00:50<00:24, 34766.09it/s]\u001b[A\n",
            "Read word2vec:  57%|█████▋    | 1134974/2000000 [00:50<00:25, 34414.40it/s]\u001b[A\n",
            "Read word2vec:  57%|█████▋    | 1138418/2000000 [00:50<00:25, 34270.98it/s]\u001b[A\n",
            "Read word2vec:  57%|█████▋    | 1141847/2000000 [00:50<00:25, 33994.78it/s]\u001b[A\n",
            "Read word2vec:  57%|█████▋    | 1145248/2000000 [00:50<00:25, 32974.62it/s]\u001b[A\n",
            "Read word2vec:  57%|█████▋    | 1148615/2000000 [00:50<00:25, 33175.72it/s]\u001b[A\n",
            "Read word2vec:  58%|█████▊    | 1152039/2000000 [00:51<00:25, 33486.39it/s]\u001b[A\n",
            "Read word2vec:  58%|█████▊    | 1155526/2000000 [00:51<00:24, 33894.41it/s]\u001b[A\n",
            "Read word2vec:  58%|█████▊    | 1159054/2000000 [00:51<00:24, 34302.99it/s]\u001b[A\n",
            "Read word2vec:  58%|█████▊    | 1162743/2000000 [00:51<00:23, 35071.99it/s]\u001b[A\n",
            "Read word2vec:  58%|█████▊    | 1166253/2000000 [00:51<00:23, 34833.68it/s]\u001b[A\n",
            "Read word2vec:  58%|█████▊    | 1169751/2000000 [00:51<00:23, 34876.09it/s]\u001b[A\n",
            "Read word2vec:  59%|█████▊    | 1173437/2000000 [00:51<00:23, 35466.05it/s]\u001b[A\n",
            "Read word2vec:  59%|█████▉    | 1177109/2000000 [00:51<00:22, 35839.36it/s]\u001b[A\n",
            "Read word2vec:  59%|█████▉    | 1180695/2000000 [00:51<00:23, 35491.11it/s]\u001b[A\n",
            "Read word2vec:  59%|█████▉    | 1184246/2000000 [00:51<00:23, 35257.54it/s]\u001b[A\n",
            "Read word2vec:  59%|█████▉    | 1187882/2000000 [00:52<00:22, 35582.96it/s]\u001b[A\n",
            "Read word2vec:  60%|█████▉    | 1191636/2000000 [00:52<00:22, 36165.19it/s]\u001b[A\n",
            "Read word2vec:  60%|█████▉    | 1195254/2000000 [00:52<00:22, 35802.15it/s]\u001b[A\n",
            "Read word2vec:  60%|█████▉    | 1198836/2000000 [00:52<00:22, 35613.42it/s]\u001b[A\n",
            "Read word2vec:  60%|██████    | 1202399/2000000 [00:52<00:22, 35155.72it/s]\u001b[A\n",
            "Read word2vec:  60%|██████    | 1205917/2000000 [00:52<00:22, 35009.58it/s]\u001b[A\n",
            "Read word2vec:  60%|██████    | 1209508/2000000 [00:52<00:22, 35275.29it/s]\u001b[A\n",
            "Read word2vec:  61%|██████    | 1213180/2000000 [00:52<00:22, 35702.01it/s]\u001b[A\n",
            "Read word2vec:  61%|██████    | 1216752/2000000 [00:52<00:22, 34487.85it/s]\u001b[A\n",
            "Read word2vec:  61%|██████    | 1220341/2000000 [00:53<00:22, 34895.44it/s]\u001b[A\n",
            "Read word2vec:  61%|██████    | 1223940/2000000 [00:53<00:22, 35215.97it/s]\u001b[A\n",
            "Read word2vec:  61%|██████▏   | 1227603/2000000 [00:53<00:21, 35632.30it/s]\u001b[A\n",
            "Read word2vec:  62%|██████▏   | 1231172/2000000 [00:53<00:21, 35563.19it/s]\u001b[A\n",
            "Read word2vec:  62%|██████▏   | 1234774/2000000 [00:53<00:21, 35698.24it/s]\u001b[A\n",
            "Read word2vec:  62%|██████▏   | 1238347/2000000 [00:53<00:21, 35615.35it/s]\u001b[A\n",
            "Read word2vec:  62%|██████▏   | 1241911/2000000 [00:53<00:21, 35619.59it/s]\u001b[A\n",
            "Read word2vec:  62%|██████▏   | 1245687/2000000 [00:53<00:20, 36257.42it/s]\u001b[A\n",
            "Read word2vec:  62%|██████▏   | 1249403/2000000 [00:53<00:20, 36525.48it/s]\u001b[A\n",
            "Read word2vec:  63%|██████▎   | 1253057/2000000 [00:53<00:21, 34406.80it/s]\u001b[A\n",
            "Read word2vec:  63%|██████▎   | 1256524/2000000 [00:54<00:21, 34397.37it/s]\u001b[A\n",
            "Read word2vec:  63%|██████▎   | 1260270/2000000 [00:54<00:20, 35284.15it/s]\u001b[A\n",
            "Read word2vec:  63%|██████▎   | 1263814/2000000 [00:54<00:20, 35324.03it/s]\u001b[A\n",
            "Read word2vec:  63%|██████▎   | 1267567/2000000 [00:54<00:20, 35974.88it/s]\u001b[A\n",
            "Read word2vec:  64%|██████▎   | 1271174/2000000 [00:54<00:20, 35865.27it/s]\u001b[A\n",
            "Read word2vec:  64%|██████▎   | 1274785/2000000 [00:54<00:20, 35936.16it/s]\u001b[A\n",
            "Read word2vec:  64%|██████▍   | 1278383/2000000 [00:54<00:20, 35545.74it/s]\u001b[A\n",
            "Read word2vec:  64%|██████▍   | 1281956/2000000 [00:54<00:20, 35599.00it/s]\u001b[A\n",
            "Read word2vec:  64%|██████▍   | 1285519/2000000 [00:54<00:20, 35338.00it/s]\u001b[A\n",
            "Read word2vec:  64%|██████▍   | 1289055/2000000 [00:54<00:21, 32405.76it/s]\u001b[A\n",
            "Read word2vec:  65%|██████▍   | 1292503/2000000 [00:55<00:21, 32983.86it/s]\u001b[A\n",
            "Read word2vec:  65%|██████▍   | 1295884/2000000 [00:55<00:21, 33215.55it/s]\u001b[A\n",
            "Read word2vec:  65%|██████▍   | 1299420/2000000 [00:55<00:20, 33835.55it/s]\u001b[A\n",
            "Read word2vec:  65%|██████▌   | 1303024/2000000 [00:55<00:20, 34480.25it/s]\u001b[A\n",
            "Read word2vec:  65%|██████▌   | 1306642/2000000 [00:55<00:19, 34978.33it/s]\u001b[A\n",
            "Read word2vec:  66%|██████▌   | 1310153/2000000 [00:55<00:20, 34165.57it/s]\u001b[A\n",
            "Read word2vec:  66%|██████▌   | 1313853/2000000 [00:55<00:19, 34991.83it/s]\u001b[A\n",
            "Read word2vec:  66%|██████▌   | 1317363/2000000 [00:55<00:19, 34204.73it/s]\u001b[A\n",
            "Read word2vec:  66%|██████▌   | 1320794/2000000 [00:55<00:19, 34064.89it/s]\u001b[A\n",
            "Read word2vec:  66%|██████▌   | 1324208/2000000 [00:56<00:19, 33838.57it/s]\u001b[A\n",
            "Read word2vec:  66%|██████▋   | 1327597/2000000 [00:56<00:19, 33823.27it/s]\u001b[A\n",
            "Read word2vec:  67%|██████▋   | 1330983/2000000 [00:56<00:20, 33404.42it/s]\u001b[A\n",
            "Read word2vec:  67%|██████▋   | 1334490/2000000 [00:56<00:19, 33889.43it/s]\u001b[A\n",
            "Read word2vec:  67%|██████▋   | 1338124/2000000 [00:56<00:19, 34613.47it/s]\u001b[A\n",
            "Read word2vec:  67%|██████▋   | 1341698/2000000 [00:56<00:18, 34944.52it/s]\u001b[A\n",
            "Read word2vec:  67%|██████▋   | 1345195/2000000 [00:56<00:19, 33679.48it/s]\u001b[A\n",
            "Read word2vec:  67%|██████▋   | 1348637/2000000 [00:56<00:19, 33884.82it/s]\u001b[A\n",
            "Read word2vec:  68%|██████▊   | 1352034/2000000 [00:56<00:19, 33783.05it/s]\u001b[A\n",
            "Read word2vec:  68%|██████▊   | 1355551/2000000 [00:56<00:18, 34189.91it/s]\u001b[A\n",
            "Read word2vec:  68%|██████▊   | 1358983/2000000 [00:57<00:18, 34222.00it/s]\u001b[A\n",
            "Read word2vec:  68%|██████▊   | 1362604/2000000 [00:57<00:18, 34811.74it/s]\u001b[A\n",
            "Read word2vec:  68%|██████▊   | 1366089/2000000 [00:57<00:18, 34276.81it/s]\u001b[A\n",
            "Read word2vec:  68%|██████▊   | 1369615/2000000 [00:57<00:18, 34566.75it/s]\u001b[A\n",
            "Read word2vec:  69%|██████▊   | 1373139/2000000 [00:57<00:18, 34760.43it/s]\u001b[A\n",
            "Read word2vec:  69%|██████▉   | 1376664/2000000 [00:57<00:17, 34903.69it/s]\u001b[A\n",
            "Read word2vec:  69%|██████▉   | 1380157/2000000 [00:57<00:17, 34547.51it/s]\u001b[A\n",
            "Read word2vec:  69%|██████▉   | 1383614/2000000 [00:57<00:18, 34050.33it/s]\u001b[A\n",
            "Read word2vec:  69%|██████▉   | 1387022/2000000 [00:57<00:18, 33840.77it/s]\u001b[A\n",
            "Read word2vec:  70%|██████▉   | 1390485/2000000 [00:57<00:17, 34070.61it/s]\u001b[A\n",
            "Read word2vec:  70%|██████▉   | 1393894/2000000 [00:58<00:18, 32792.21it/s]\u001b[A\n",
            "Read word2vec:  70%|██████▉   | 1397547/2000000 [00:58<00:17, 33874.20it/s]\u001b[A\n",
            "Read word2vec:  70%|███████   | 1400946/2000000 [00:58<00:17, 33880.68it/s]\u001b[A\n",
            "Read word2vec:  70%|███████   | 1404632/2000000 [00:58<00:17, 34758.27it/s]\u001b[A\n",
            "Read word2vec:  70%|███████   | 1408124/2000000 [00:58<00:17, 34804.04it/s]\u001b[A\n",
            "Read word2vec:  71%|███████   | 1411735/2000000 [00:58<00:16, 35190.00it/s]\u001b[A\n",
            "Read word2vec:  71%|███████   | 1415308/2000000 [00:58<00:16, 35348.07it/s]\u001b[A\n",
            "Read word2vec:  71%|███████   | 1419009/2000000 [00:58<00:16, 35844.23it/s]\u001b[A\n",
            "Read word2vec:  71%|███████   | 1422596/2000000 [00:58<00:16, 35140.12it/s]\u001b[A\n",
            "Read word2vec:  71%|███████▏  | 1426242/2000000 [00:58<00:16, 35526.26it/s]\u001b[A\n",
            "Read word2vec:  71%|███████▏  | 1429799/2000000 [00:59<00:16, 34985.63it/s]\u001b[A\n",
            "Read word2vec:  72%|███████▏  | 1433302/2000000 [00:59<00:16, 34672.75it/s]\u001b[A\n",
            "Read word2vec:  72%|███████▏  | 1436808/2000000 [00:59<00:16, 34784.14it/s]\u001b[A\n",
            "Read word2vec:  72%|███████▏  | 1440499/2000000 [00:59<00:15, 35409.43it/s]\u001b[A\n",
            "Read word2vec:  72%|███████▏  | 1444240/2000000 [00:59<00:15, 36003.25it/s]\u001b[A\n",
            "Read word2vec:  72%|███████▏  | 1447843/2000000 [00:59<00:15, 35908.75it/s]\u001b[A\n",
            "Read word2vec:  73%|███████▎  | 1451469/2000000 [00:59<00:15, 36011.67it/s]\u001b[A\n",
            "Read word2vec:  73%|███████▎  | 1455072/2000000 [00:59<00:15, 35793.24it/s]\u001b[A\n",
            "Read word2vec:  73%|███████▎  | 1458714/2000000 [00:59<00:15, 35956.37it/s]\u001b[A\n",
            "Read word2vec:  73%|███████▎  | 1462311/2000000 [00:59<00:15, 35496.14it/s]\u001b[A\n",
            "Read word2vec:  73%|███████▎  | 1465863/2000000 [01:00<00:15, 35075.02it/s]\u001b[A\n",
            "Read word2vec:  73%|███████▎  | 1469373/2000000 [01:00<00:15, 34545.46it/s]\u001b[A\n",
            "Read word2vec:  74%|███████▎  | 1472854/2000000 [01:00<00:15, 34619.85it/s]\u001b[A\n",
            "Read word2vec:  74%|███████▍  | 1476377/2000000 [01:00<00:15, 34798.78it/s]\u001b[A\n",
            "Read word2vec:  74%|███████▍  | 1480040/2000000 [01:00<00:14, 35341.42it/s]\u001b[A\n",
            "Read word2vec:  74%|███████▍  | 1483735/2000000 [01:00<00:14, 35819.12it/s]\u001b[A\n",
            "Read word2vec:  74%|███████▍  | 1487320/2000000 [01:00<00:14, 35825.31it/s]\u001b[A\n",
            "Read word2vec:  75%|███████▍  | 1490904/2000000 [01:00<00:14, 34871.29it/s]\u001b[A\n",
            "Read word2vec:  75%|███████▍  | 1494398/2000000 [01:00<00:14, 34863.07it/s]\u001b[A\n",
            "Read word2vec:  75%|███████▍  | 1497889/2000000 [01:00<00:14, 34773.71it/s]\u001b[A\n",
            "Read word2vec:  75%|███████▌  | 1501370/2000000 [01:01<00:14, 34770.40it/s]\u001b[A\n",
            "Read word2vec:  75%|███████▌  | 1504905/2000000 [01:01<00:14, 34939.63it/s]\u001b[A\n",
            "Read word2vec:  75%|███████▌  | 1508402/2000000 [01:01<00:14, 34948.62it/s]\u001b[A\n",
            "Read word2vec:  76%|███████▌  | 1511898/2000000 [01:01<00:13, 34931.04it/s]\u001b[A\n",
            "Read word2vec:  76%|███████▌  | 1515460/2000000 [01:01<00:13, 35134.11it/s]\u001b[A\n",
            "Read word2vec:  76%|███████▌  | 1519097/2000000 [01:01<00:13, 35500.17it/s]\u001b[A\n",
            "Read word2vec:  76%|███████▌  | 1522648/2000000 [01:01<00:13, 34793.80it/s]\u001b[A\n",
            "Read word2vec:  76%|███████▋  | 1526316/2000000 [01:01<00:13, 35329.35it/s]\u001b[A\n",
            "Read word2vec:  76%|███████▋  | 1529853/2000000 [01:01<00:13, 35015.42it/s]\u001b[A\n",
            "Read word2vec:  77%|███████▋  | 1533358/2000000 [01:02<00:13, 34858.49it/s]\u001b[A\n",
            "Read word2vec:  77%|███████▋  | 1536846/2000000 [01:02<00:13, 34604.47it/s]\u001b[A\n",
            "Read word2vec:  77%|███████▋  | 1540351/2000000 [01:02<00:13, 34733.71it/s]\u001b[A\n",
            "Read word2vec:  77%|███████▋  | 1544018/2000000 [01:02<00:12, 35307.64it/s]\u001b[A\n",
            "Read word2vec:  77%|███████▋  | 1547636/2000000 [01:02<00:12, 35517.37it/s]\u001b[A\n",
            "Read word2vec:  78%|███████▊  | 1551189/2000000 [01:02<00:12, 35006.58it/s]\u001b[A\n",
            "Read word2vec:  78%|███████▊  | 1554860/2000000 [01:02<00:12, 35503.43it/s]\u001b[A\n",
            "Read word2vec:  78%|███████▊  | 1558413/2000000 [01:02<00:12, 35499.74it/s]\u001b[A\n",
            "Read word2vec:  78%|███████▊  | 1561965/2000000 [01:02<00:12, 35499.26it/s]\u001b[A\n",
            "Read word2vec:  78%|███████▊  | 1565558/2000000 [01:02<00:12, 35627.47it/s]\u001b[A\n",
            "Read word2vec:  78%|███████▊  | 1569122/2000000 [01:03<00:12, 35567.84it/s]\u001b[A\n",
            "Read word2vec:  79%|███████▊  | 1572680/2000000 [01:03<00:12, 34889.33it/s]\u001b[A\n",
            "Read word2vec:  79%|███████▉  | 1576283/2000000 [01:03<00:12, 35221.91it/s]\u001b[A\n",
            "Read word2vec:  79%|███████▉  | 1579865/2000000 [01:03<00:11, 35396.71it/s]\u001b[A\n",
            "Read word2vec:  79%|███████▉  | 1583450/2000000 [01:03<00:11, 35531.30it/s]\u001b[A\n",
            "Read word2vec:  79%|███████▉  | 1587213/2000000 [01:03<00:11, 36156.13it/s]\u001b[A\n",
            "Read word2vec:  80%|███████▉  | 1590831/2000000 [01:03<00:11, 36049.78it/s]\u001b[A\n",
            "Read word2vec:  80%|███████▉  | 1594438/2000000 [01:03<00:11, 35336.35it/s]\u001b[A\n",
            "Read word2vec:  80%|███████▉  | 1597976/2000000 [01:03<00:11, 34984.57it/s]\u001b[A\n",
            "Read word2vec:  80%|████████  | 1601547/2000000 [01:03<00:11, 35196.48it/s]\u001b[A\n",
            "Read word2vec:  80%|████████  | 1605184/2000000 [01:04<00:11, 35534.57it/s]\u001b[A\n",
            "Read word2vec:  80%|████████  | 1608740/2000000 [01:04<00:11, 35096.89it/s]\u001b[A\n",
            "Read word2vec:  81%|████████  | 1612275/2000000 [01:04<00:11, 35171.07it/s]\u001b[A\n",
            "Read word2vec:  81%|████████  | 1615794/2000000 [01:04<00:11, 34825.83it/s]\u001b[A\n",
            "Read word2vec:  81%|████████  | 1619328/2000000 [01:04<00:10, 34975.48it/s]\u001b[A\n",
            "Read word2vec:  81%|████████  | 1622834/2000000 [01:04<00:10, 35000.06it/s]\u001b[A\n",
            "Read word2vec:  81%|████████▏ | 1626564/2000000 [01:04<00:10, 35680.80it/s]\u001b[A\n",
            "Read word2vec:  82%|████████▏ | 1630134/2000000 [01:04<00:10, 34829.07it/s]\u001b[A\n",
            "Read word2vec:  82%|████████▏ | 1633622/2000000 [01:04<00:10, 34274.67it/s]\u001b[A\n",
            "Read word2vec:  82%|████████▏ | 1637295/2000000 [01:04<00:10, 34988.39it/s]\u001b[A\n",
            "Read word2vec:  82%|████████▏ | 1640920/2000000 [01:05<00:10, 35359.67it/s]\u001b[A\n",
            "Read word2vec:  82%|████████▏ | 1644461/2000000 [01:05<00:10, 34762.48it/s]\u001b[A\n",
            "Read word2vec:  82%|████████▏ | 1647942/2000000 [01:05<00:10, 34533.01it/s]\u001b[A\n",
            "Read word2vec:  83%|████████▎ | 1651621/2000000 [01:05<00:09, 35195.88it/s]\u001b[A\n",
            "Read word2vec:  83%|████████▎ | 1655328/2000000 [01:05<00:09, 35749.22it/s]\u001b[A\n",
            "Read word2vec:  83%|████████▎ | 1659018/2000000 [01:05<00:09, 36089.95it/s]\u001b[A\n",
            "Read word2vec:  83%|████████▎ | 1662630/2000000 [01:05<00:09, 35876.21it/s]\u001b[A\n",
            "Read word2vec:  83%|████████▎ | 1666220/2000000 [01:05<00:09, 35509.81it/s]\u001b[A\n",
            "Read word2vec:  83%|████████▎ | 1669924/2000000 [01:05<00:09, 35961.72it/s]\u001b[A\n",
            "Read word2vec:  84%|████████▎ | 1673523/2000000 [01:05<00:09, 35225.98it/s]\u001b[A\n",
            "Read word2vec:  84%|████████▍ | 1677050/2000000 [01:06<00:09, 35229.91it/s]\u001b[A\n",
            "Read word2vec:  84%|████████▍ | 1680576/2000000 [01:06<00:09, 34000.18it/s]\u001b[A\n",
            "Read word2vec:  84%|████████▍ | 1683986/2000000 [01:06<00:09, 33786.87it/s]\u001b[A\n",
            "Read word2vec:  84%|████████▍ | 1687548/2000000 [01:06<00:09, 34317.78it/s]\u001b[A\n",
            "Read word2vec:  85%|████████▍ | 1691334/2000000 [01:06<00:08, 35357.30it/s]\u001b[A\n",
            "Read word2vec:  85%|████████▍ | 1694877/2000000 [01:06<00:08, 35017.49it/s]\u001b[A\n",
            "Read word2vec:  85%|████████▍ | 1698384/2000000 [01:06<00:08, 34931.61it/s]\u001b[A\n",
            "Read word2vec:  85%|████████▌ | 1702154/2000000 [01:06<00:08, 35749.83it/s]\u001b[A\n",
            "Read word2vec:  85%|████████▌ | 1705733/2000000 [01:06<00:08, 35388.05it/s]\u001b[A\n",
            "Read word2vec:  85%|████████▌ | 1709497/2000000 [01:06<00:08, 36051.96it/s]\u001b[A\n",
            "Read word2vec:  86%|████████▌ | 1713106/2000000 [01:07<00:07, 35886.54it/s]\u001b[A\n",
            "Read word2vec:  86%|████████▌ | 1716697/2000000 [01:07<00:08, 34556.44it/s]\u001b[A\n",
            "Read word2vec:  86%|████████▌ | 1720321/2000000 [01:07<00:07, 35042.96it/s]\u001b[A\n",
            "Read word2vec:  86%|████████▌ | 1724088/2000000 [01:07<00:07, 35811.56it/s]\u001b[A\n",
            "Read word2vec:  86%|████████▋ | 1727791/2000000 [01:07<00:07, 36170.32it/s]\u001b[A\n",
            "Read word2vec:  87%|████████▋ | 1731415/2000000 [01:07<00:07, 35696.29it/s]\u001b[A\n",
            "Read word2vec:  87%|████████▋ | 1735018/2000000 [01:07<00:07, 35791.98it/s]\u001b[A\n",
            "Read word2vec:  87%|████████▋ | 1738602/2000000 [01:07<00:07, 34545.99it/s]\u001b[A\n",
            "Read word2vec:  87%|████████▋ | 1742424/2000000 [01:07<00:07, 35611.01it/s]\u001b[A\n",
            "Read word2vec:  87%|████████▋ | 1745997/2000000 [01:08<00:07, 34866.82it/s]\u001b[A\n",
            "Read word2vec:  87%|████████▋ | 1749700/2000000 [01:08<00:07, 35491.76it/s]\u001b[A\n",
            "Read word2vec:  88%|████████▊ | 1753259/2000000 [01:08<00:07, 34388.65it/s]\u001b[A\n",
            "Read word2vec:  88%|████████▊ | 1756936/2000000 [01:08<00:06, 35075.05it/s]\u001b[A\n",
            "Read word2vec:  88%|████████▊ | 1760550/2000000 [01:08<00:06, 35384.12it/s]\u001b[A\n",
            "Read word2vec:  88%|████████▊ | 1764097/2000000 [01:08<00:06, 35334.39it/s]\u001b[A\n",
            "Read word2vec:  88%|████████▊ | 1767759/2000000 [01:08<00:06, 35713.98it/s]\u001b[A\n",
            "Read word2vec:  89%|████████▊ | 1771336/2000000 [01:08<00:06, 35626.19it/s]\u001b[A\n",
            "Read word2vec:  89%|████████▊ | 1774937/2000000 [01:08<00:06, 35739.14it/s]\u001b[A\n",
            "Read word2vec:  89%|████████▉ | 1778528/2000000 [01:08<00:06, 35785.59it/s]\u001b[A\n",
            "Read word2vec:  89%|████████▉ | 1782109/2000000 [01:09<00:06, 35158.41it/s]\u001b[A\n",
            "Read word2vec:  89%|████████▉ | 1785629/2000000 [01:09<00:06, 34756.78it/s]\u001b[A\n",
            "Read word2vec:  89%|████████▉ | 1789108/2000000 [01:09<00:06, 33611.89it/s]\u001b[A\n",
            "Read word2vec:  90%|████████▉ | 1792709/2000000 [01:09<00:06, 34303.49it/s]\u001b[A\n",
            "Read word2vec:  90%|████████▉ | 1796442/2000000 [01:09<00:05, 35185.17it/s]\u001b[A\n",
            "Read word2vec:  90%|█████████ | 1800019/2000000 [01:09<00:05, 35351.63it/s]\u001b[A\n",
            "Read word2vec:  90%|█████████ | 1803578/2000000 [01:09<00:05, 35422.19it/s]\u001b[A\n",
            "Read word2vec:  90%|█████████ | 1807201/2000000 [01:09<00:05, 35661.92it/s]\u001b[A\n",
            "Read word2vec:  91%|█████████ | 1810862/2000000 [01:09<00:05, 35943.98it/s]\u001b[A\n",
            "Read word2vec:  91%|█████████ | 1814459/2000000 [01:09<00:05, 35008.63it/s]\u001b[A\n",
            "Read word2vec:  91%|█████████ | 1818220/2000000 [01:10<00:05, 35770.69it/s]\u001b[A\n",
            "Read word2vec:  91%|█████████ | 1821864/2000000 [01:10<00:04, 35968.02it/s]\u001b[A\n",
            "Read word2vec:  91%|█████████▏| 1825466/2000000 [01:10<00:05, 34192.42it/s]\u001b[A\n",
            "Read word2vec:  91%|█████████▏| 1829061/2000000 [01:10<00:04, 34692.80it/s]\u001b[A\n",
            "Read word2vec:  92%|█████████▏| 1832806/2000000 [01:10<00:04, 35494.54it/s]\u001b[A\n",
            "Read word2vec:  92%|█████████▏| 1836370/2000000 [01:10<00:04, 35427.19it/s]\u001b[A\n",
            "Read word2vec:  92%|█████████▏| 1839923/2000000 [01:10<00:04, 35425.01it/s]\u001b[A\n",
            "Read word2vec:  92%|█████████▏| 1843523/2000000 [01:10<00:04, 35595.03it/s]\u001b[A\n",
            "Read word2vec:  92%|█████████▏| 1847189/2000000 [01:10<00:04, 35909.09it/s]\u001b[A\n",
            "Read word2vec:  93%|█████████▎| 1850791/2000000 [01:11<00:04, 35940.98it/s]\u001b[A\n",
            "Read word2vec:  93%|█████████▎| 1854435/2000000 [01:11<00:04, 36086.82it/s]\u001b[A\n",
            "Read word2vec:  93%|█████████▎| 1858046/2000000 [01:11<00:03, 36071.02it/s]\u001b[A\n",
            "Read word2vec:  93%|█████████▎| 1861655/2000000 [01:11<00:03, 35283.88it/s]\u001b[A\n",
            "Read word2vec:  93%|█████████▎| 1865188/2000000 [01:11<00:03, 35234.22it/s]\u001b[A\n",
            "Read word2vec:  93%|█████████▎| 1868846/2000000 [01:11<00:03, 35630.67it/s]\u001b[A\n",
            "Read word2vec:  94%|█████████▎| 1872412/2000000 [01:11<00:03, 35309.29it/s]\u001b[A\n",
            "Read word2vec:  94%|█████████▍| 1876090/2000000 [01:11<00:03, 35742.87it/s]\u001b[A\n",
            "Read word2vec:  94%|█████████▍| 1879727/2000000 [01:11<00:03, 35928.36it/s]\u001b[A\n",
            "Read word2vec:  94%|█████████▍| 1883457/2000000 [01:11<00:03, 36336.82it/s]\u001b[A\n",
            "Read word2vec:  94%|█████████▍| 1887093/2000000 [01:12<00:03, 36014.28it/s]\u001b[A\n",
            "Read word2vec:  95%|█████████▍| 1890703/2000000 [01:12<00:03, 36035.81it/s]\u001b[A\n",
            "Read word2vec:  95%|█████████▍| 1894308/2000000 [01:12<00:02, 35410.30it/s]\u001b[A\n",
            "Read word2vec:  95%|█████████▍| 1897852/2000000 [01:12<00:02, 35090.25it/s]\u001b[A\n",
            "Read word2vec:  95%|█████████▌| 1901395/2000000 [01:12<00:02, 35189.07it/s]\u001b[A\n",
            "Read word2vec:  95%|█████████▌| 1905160/2000000 [01:12<00:02, 35916.41it/s]\u001b[A\n",
            "Read word2vec:  95%|█████████▌| 1908754/2000000 [01:12<00:02, 35489.47it/s]\u001b[A\n",
            "Read word2vec:  96%|█████████▌| 1912306/2000000 [01:12<00:02, 35300.29it/s]\u001b[A\n",
            "Read word2vec:  96%|█████████▌| 1915994/2000000 [01:12<00:02, 35767.11it/s]\u001b[A\n",
            "Read word2vec:  96%|█████████▌| 1919846/2000000 [01:12<00:02, 36584.62it/s]\u001b[A\n",
            "Read word2vec:  96%|█████████▌| 1923507/2000000 [01:13<00:02, 36270.10it/s]\u001b[A\n",
            "Read word2vec:  96%|█████████▋| 1927136/2000000 [01:13<00:02, 35832.97it/s]\u001b[A\n",
            "Read word2vec:  97%|█████████▋| 1930722/2000000 [01:13<00:01, 35524.32it/s]\u001b[A\n",
            "Read word2vec:  97%|█████████▋| 1934277/2000000 [01:13<00:01, 34757.69it/s]\u001b[A\n",
            "Read word2vec:  97%|█████████▋| 1937835/2000000 [01:13<00:01, 34996.28it/s]\u001b[A\n",
            "Read word2vec:  97%|█████████▋| 1941433/2000000 [01:13<00:01, 35284.42it/s]\u001b[A\n",
            "Read word2vec:  97%|█████████▋| 1944965/2000000 [01:13<00:01, 34404.50it/s]\u001b[A\n",
            "Read word2vec:  97%|█████████▋| 1948554/2000000 [01:13<00:01, 34836.79it/s]\u001b[A\n",
            "Read word2vec:  98%|█████████▊| 1952043/2000000 [01:13<00:01, 34707.07it/s]\u001b[A\n",
            "Read word2vec:  98%|█████████▊| 1955839/2000000 [01:13<00:01, 35666.55it/s]\u001b[A\n",
            "Read word2vec:  98%|█████████▊| 1959410/2000000 [01:14<00:01, 34975.39it/s]\u001b[A\n",
            "Read word2vec:  98%|█████████▊| 1963048/2000000 [01:14<00:01, 35386.79it/s]\u001b[A\n",
            "Read word2vec:  98%|█████████▊| 1966592/2000000 [01:14<00:00, 35385.25it/s]\u001b[A\n",
            "Read word2vec:  99%|█████████▊| 1970134/2000000 [01:14<00:00, 34611.48it/s]\u001b[A\n",
            "Read word2vec:  99%|█████████▊| 1973708/2000000 [01:14<00:00, 34926.62it/s]\u001b[A\n",
            "Read word2vec:  99%|█████████▉| 1977206/2000000 [01:14<00:00, 34587.03it/s]\u001b[A\n",
            "Read word2vec:  99%|█████████▉| 1980761/2000000 [01:14<00:00, 34868.97it/s]\u001b[A\n",
            "Read word2vec:  99%|█████████▉| 1984251/2000000 [01:14<00:00, 34002.47it/s]\u001b[A\n",
            "Read word2vec:  99%|█████████▉| 1987798/2000000 [01:14<00:00, 34429.34it/s]\u001b[A\n",
            "Read word2vec: 100%|█████████▉| 1991298/2000000 [01:14<00:00, 34595.75it/s]\u001b[A\n",
            "Read word2vec: 100%|█████████▉| 1994762/2000000 [01:15<00:00, 34607.61it/s]\u001b[A\n",
            "Read word2vec: 100%|██████████| 2000000/2000000 [01:15<00:00, 26581.26it/s]\n"
          ]
        }
      ],
      "source": [
        "word2index = {'PAD': 0}\n",
        "vectors = []\n",
        "    \n",
        "word2vec_file = open('cc.ru.300.vec')\n",
        "    \n",
        "n_words, embedding_dim = word2vec_file.readline().split()\n",
        "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
        "\n",
        "# Zero vector for PAD\n",
        "vectors.append(np.zeros((1, embedding_dim)))\n",
        "\n",
        "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
        "\n",
        "while True:\n",
        "\n",
        "    line = word2vec_file.readline().strip()\n",
        "\n",
        "    if not line:\n",
        "        break\n",
        "        \n",
        "    current_parts = line.split()\n",
        "\n",
        "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
        "\n",
        "    if current_word in word2freq:\n",
        "\n",
        "        word2index[current_word] = len(word2index)\n",
        "\n",
        "        current_vectors = current_parts[-embedding_dim:]\n",
        "        current_vectors = np.array(list(map(float, current_vectors)))\n",
        "        current_vectors = np.expand_dims(current_vectors, 0)\n",
        "\n",
        "        vectors.append(current_vectors)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "word2vec_file.close()\n",
        "\n",
        "vectors = np.concatenate(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYJMzgpnW-A7",
        "outputId": "4a2f2c4a-1c4d-442b-d329-3ff544e476d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117619"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ],
      "source": [
        "len(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE06fafiW-A8",
        "outputId": "0e098636-b675-415f-b7ae-916a29c70e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мы не знаем 2.50 % слов в датасете\n",
            "Количество неизвестных слов 34561 из 152179, то есть 22.71 % уникальных слов в словаре\n",
            "В среднем каждое встречается 1.98 раз\n",
            "\n",
            "Топ 5 невошедших слов:\n",
            "??? с количеством вхождениий - 3641\n",
            "?? с количеством вхождениий - 2448\n",
            "!!! с количеством вхождениий - 2214\n",
            "?) с количеством вхождениий - 2069\n",
            "\"? с количеством вхождениий - 1429\n"
          ]
        }
      ],
      "source": [
        "unk_words = [word for word in word2freq if word not in word2index]\n",
        "unk_counts = [word2freq[word] for word in unk_words]\n",
        "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
        "\n",
        "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
        "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
        "\n",
        "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
        "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
        "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
        "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
        "print()\n",
        "print('Топ 5 невошедших слов:')\n",
        "\n",
        "for i in range(5):\n",
        "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFPNApUjW-A9"
      },
      "source": [
        "# Потеря 2.5 % слов в датасете\n",
        "Эта ситуация не то, чтобы сильно плохая, в учебных целях нормально, к тому же в среднем они редко встречаются. Вы можете поиграть с предобработкой."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "_fo1fB6JW-A-"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEKAjCg3W-BA"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "D19pDyQBW-BA"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(128, 64, 1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "Yxsxr7edW-BB"
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZy0lKr2W-BC",
        "outputId": "44edb706-4e19-492d-b7de-4bb1ab3dfd10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900 ms ± 184 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s611e34SW-BE"
      },
      "source": [
        "# А что GPU?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjFlWdgtW-BE",
        "outputId": "26a5bf4d-4368-42ea-eab9-5d5c6c8fda74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Доступна ли видеокарта: True\n",
            "Если недоступна, поменяйте runtime, если в колабе\n"
          ]
        }
      ],
      "source": [
        "print('Доступна ли видеокарта:', torch.cuda.is_available())\n",
        "print('Если недоступна, поменяйте runtime, если в колабе')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "jaMMD5CDW-BG"
      },
      "outputs": [],
      "source": [
        "# универсальных способ задать device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# если доступна gpu, то давайте ее использовать, но в этом задании должны использовать"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "GeQCiSYdW-BH"
      },
      "outputs": [],
      "source": [
        "# перенесли x на gpu\n",
        "x_gpu = x.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "S_qUdMcbW-BJ"
      },
      "outputs": [],
      "source": [
        "# зададим lstm на gpu\n",
        "lstm_gpu = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "lstm_gpu = lstm_gpu.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSUQmRgtW-BK",
        "outputId": "3262f04c-516f-42ab-de84-ebf3642d6611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15.1 ms ± 77.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm_gpu(x_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPvqNWkQW-BM"
      },
      "source": [
        "# У меня на 1070 TI скорость уменьшилась с 381мс до 41мс, то есть в 9.29 раз"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "FaPKGO5aW-BN"
      },
      "outputs": [],
      "source": [
        "# если у нас модель на гпу, а то, что мы туда подаем нет, то работать не будет\n",
        "# справедлива и обратная ситуация\n",
        "\n",
        "# выскочит ошибка\n",
        "# посмотрите на нее, возможно, вы еще встретитесь\n",
        "# pred = lstm_gpu(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NX5HHDOW-BO"
      },
      "source": [
        "# Важные и не очень интуитивные моменты про LSTM и CNN в торче"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKr22rklW-BP"
      },
      "source": [
        "По умолчанию LSTM принимает данные с такой размерностью:\n",
        "```python\n",
        "(seq_len, batch, input_size)\n",
        "```\n",
        "Сделано это с целью оптимизации на более низком уровне.  \n",
        "Мы оперируем такими объектами:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "Чтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\n",
        "либо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n",
        "[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bny8SvCgW-BQ"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "vc-bLok2W-BQ"
      },
      "outputs": [],
      "source": [
        "# первый способ\n",
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "\n",
        "pred, mem = lstm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHpit-1tW-BR",
        "outputId": "62aac9fa-9db6-4159-85ae-70813bf835a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "ru_WzGSJW-BS"
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512)\n",
        "\n",
        "# меняем размерность batch и seq_len местами\n",
        "x_transposed = x.transpose(0, 1)\n",
        "pred_transposed, mem = lstm(x_transposed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHdBavTWW-BT",
        "outputId": "82ad5325-4c52-4e73-cfaa-dea2cd51a159"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ],
      "source": [
        "# у нас все еще осталась размерность (seq_len, batch, input_size)\n",
        "pred_transposed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcxv55j7W-BV",
        "outputId": "1808cea4-fa89-4b4b-c3e9-bb8f01e5f4a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ],
      "source": [
        "# просто транспонируем еще раз\n",
        "pred = pred_transposed.transpose(0, 1)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmJt6cqkW-BW"
      },
      "source": [
        "## Conv1d & MaxPool1d\n",
        "Примерно такая же ситуация происходит со сверточными слоями и пулингами.  \n",
        "1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n",
        "[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n",
        "[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \n",
        "Ожидается такая размерность:\n",
        "```python\n",
        "(batch, input_size, seq_len)\n",
        "```\n",
        "Мы все еще хоти подавать такую размерность:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "В случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyM8Xl24W-BX",
        "outputId": "19b91a56-583e-4a93-f3cb-6e6350dca426"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grPNMjEZW-BY"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "btJ-ApiOW-BY"
      },
      "outputs": [],
      "source": [
        "# in_channels - размер входных эмбеддингов\n",
        "# out_channels - количество/какой размер эмбеддингов мы хотим получить\n",
        "# kernel_size - размер окна/н-граммы\n",
        "cnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "QIYff7YyW-Bb"
      },
      "outputs": [],
      "source": [
        "# выпадет ошибка, посмотрите какая\n",
        "# pred = cnn(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tVn6YKLW-Bd",
        "outputId": "e8256a27-2df4-4e01-fd59-74c288b39d69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ],
      "source": [
        "x_transposed = x.transpose(1, 2)\n",
        "x_transposed.shape\n",
        "# перевели в (batch, input_size, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N4w6-iWW-Be",
        "outputId": "7c3fb4e8-e189-41c9-dce3-9855fa7805a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 512, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ],
      "source": [
        "pred_transposed = cnn(x_transposed)\n",
        "pred_transposed.shape\n",
        "# осталась разрмерность (batch, output_size, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-C3_phaW-Bf",
        "outputId": "6449e7ce-640a-46e1-b2ea-e9b981a57363"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 62, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ],
      "source": [
        "# переведем обратно в (batch, seq_len, input_size)\n",
        "pred = pred_transposed.transpose(1, 2)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stBQ3yhqW-Bi"
      },
      "source": [
        "# Подготовим данные в DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "vPX_m5M4W-Bi"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV76BdN0W-Bj",
        "outputId": "2ce3299e-3bed-4612-96a5-ef6bfb41f60e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ],
      "source": [
        "'UNK' in word2index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "INB_dPAnW-Bk",
        "outputId": "e996f90e-1049-466f-d743-8a959e492860"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   category                                               text\n",
              "0  business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1       law  Может ли срочник перевестись на контракт после...\n",
              "2  business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3  business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4       law                 часть 1 статья 158 похитил телефон"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-847ba64d-68ab-41b9-b45c-163d44e6b83a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-847ba64d-68ab-41b9-b45c-163d44e6b83a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-847ba64d-68ab-41b9-b45c-163d44e6b83a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-847ba64d-68ab-41b9-b45c-163d44e6b83a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qv1mKAeW-Bl"
      },
      "source": [
        "# Замапим категории в индексы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "iHeFzZe1W-Bl"
      },
      "outputs": [],
      "source": [
        "cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3x9QhXYW-Bn",
        "outputId": "fa52ce92-ea24-4421-d600-427a4db0036e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'business': 0, 'law': 1, 'love': 2, 'relax': 3, 'food': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ],
      "source": [
        "cat_mapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "ef--8SWbW-Bo"
      },
      "outputs": [],
      "source": [
        "data.category = data.category.map(cat_mapper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc48ALg_W-Bp"
      },
      "source": [
        "# Читалка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFIQEv6nvE4c"
      },
      "source": [
        "## Что происходит ниже\n",
        "1. Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n",
        "1. Загружаем данные:\n",
        "    1. Проходимся по датасету\n",
        "    1. Предобрабатываем каждый текст в датасете\n",
        "    1. Индексируем его\n",
        "    1. Паддим до нужной длины\n",
        "1. Когда нам нужно достать пример из датасета мы берем индексированный ```x``` и соответствующий этому индексу ```y```, наш ```x``` также паддим (или ограничиваем длину) и переводим в ```torch.Tensor(x).long()```. Для ```y``` этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "ZkX8SC_sW-Bp"
      },
      "outputs": [],
      "source": [
        "class WordData(Dataset):\n",
        "    \n",
        "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.x_data = []\n",
        "        self.y_data = y_data\n",
        "        \n",
        "        self.word2index = word2index\n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "        self.pad_token = pad_token\n",
        "        self.pad_index = self.word2index[self.pad_token]\n",
        "        \n",
        "        self.load(x_data, verbose=verbose)\n",
        "        \n",
        "    @staticmethod\n",
        "    def process_text(text):\n",
        "        \n",
        "        # Место для вашей предобработки\n",
        "        \n",
        "        words = wordpunct_tokenize(text.lower())\n",
        "        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n",
        "        return words\n",
        "        \n",
        "    def load(self, data, verbose=True):\n",
        "        \n",
        "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
        "        \n",
        "        for text in data_iterator:\n",
        "            \n",
        "            words = self.process_text(text)\n",
        "            \n",
        "            indexed_words = self.indexing(words)\n",
        "            \n",
        "            self.x_data.append(indexed_words)\n",
        "    \n",
        "    def indexing(self, tokenized_text):\n",
        "\n",
        "        # здесь мы не используем токен UNK, потому что мы его специально не учили\n",
        "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
        "        # поэтому просто выбрасываем наши неизветсные слова\n",
        "        \n",
        "        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n",
        "    \n",
        "    def padding(self, sequence):\n",
        "        \n",
        "        # Ограничить длину self.sequence_length\n",
        "        # если длина меньше максимально - западить\n",
        "        if len(sequence)< self.sequence_length:\n",
        "          add_pad = self.sequence_length - len(sequence)\n",
        "          return sequence+[self.pad_index]*add_pad\n",
        "        else:\n",
        "          return sequence[:self.sequence_length]\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.x_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        x = self.x_data[idx]\n",
        "        x = self.padding(x)\n",
        "        x = torch.Tensor(x).long()\n",
        "        \n",
        "        y = self.y_data[idx]\n",
        "        \n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "R3WW8V9lyLm0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnc2nD8gW-Br",
        "outputId": "aad5cf1c-d4cc-4440-9004-699cacfbca59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading data: 100%|██████████| 214001/214001 [00:02<00:00, 82565.49it/s]\n",
            "Loading data: 100%|██████████| 23778/23778 [00:00<00:00, 90205.55it/s]\n"
          ]
        }
      ],
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "dGeftxdgW-Br"
      },
      "outputs": [],
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNkGQffBW-Bs",
        "outputId": "1bf4bc05-a347-4e8a-8a2c-3925df3518b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  26,   66, 1873,  ...,    0,    0,    0],\n",
              "        [1960, 9660, 2824,  ...,    0,    0,    0],\n",
              "        [  82,  211, 7484,  ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [  24,  276,  136,  ...,    0,    0,    0],\n",
              "        [  19,  361,   75,  ...,    0,    0,    0],\n",
              "        [  19, 1113,  241,  ...,    0,    0,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxUk4nGcW-Bt",
        "outputId": "7aaae6b7-6ca0-43c9-d469-c8d0c596c4b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 3, 1, 0, 4, 3, 0, 1, 0, 1, 3, 3, 0, 3, 3, 2, 3, 3, 1, 4, 2, 4, 2,\n",
              "        2, 1, 2, 1, 3, 1, 3, 1, 0, 3, 2, 1, 3, 1, 0, 0, 0, 1, 3, 2, 1, 3, 3, 3,\n",
              "        1, 0, 0, 4, 0, 0, 3, 0, 1, 0, 4, 4, 1, 3, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape\n",
        "# batch_size = 64\n",
        "# seq_length = 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-FdrBaPwvyQ",
        "outputId": "e31f57e6-4dea-40e6-a6ee-9eb77a934ebb"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy0dkkTIW-Bw"
      },
      "source": [
        "# Обучить нейронку"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "3wwkxZm1vE43"
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "\n",
        "class model_with_att(torch.nn.Module):\n",
        "  def __init__(self, matrix_w, n): #n - количетсво категорий\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.n = n\n",
        "        self.embeddings = matrix_w\n",
        "\n",
        "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "\n",
        "        self.LSTM = torch.nn.LSTM(input_size=300, \n",
        "                                  hidden_size=256, \n",
        "                                  num_layers=2, \n",
        "                                  batch_first=True, \n",
        "                                  dropout=0.1, \n",
        "                                  bidirectional=True) # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n",
        "        \n",
        "        self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)# три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
        "        self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "        self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "\n",
        "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "        \n",
        "        self.cnn_3gr = torch.nn.Conv1d(in_channels=256, \n",
        "                                       out_channels=128, \n",
        "                                       kernel_size=(3,), \n",
        "                                       stride=(1,))# три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
        "        self.cnn_4gr = torch.nn.Conv1d(in_channels=256, \n",
        "                                       out_channels=128, \n",
        "                                       kernel_size=(4,), \n",
        "                                       stride=(1,))\n",
        "        self.cnn_5gr = torch.nn.Conv1d(in_channels=256, \n",
        "                                       out_channels=128, \n",
        "                                       kernel_size=(5,), \n",
        "                                       stride=(1,))\n",
        "\n",
        "        self.linear_1 = torch.nn.Linear(in_features=128*3, out_features=256, bias=True)# сверху накидываем два полносвязных слоя для классификации\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear_2 = torch.nn.Linear(in_features=256, out_features=n, bias=True) \n",
        "\n",
        "        \n",
        "  def forward(self, x):\n",
        "      x_emb = self.emb_layer(x)#примените эмбеддинги\n",
        "      # транспонируйте тензор для лстм как было описано выше\n",
        "      x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "      # транспонируйте обратно\n",
        "\n",
        "      x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n",
        "      x_k = self.k_proj(x)\n",
        "      x_v = self.v_proj(x)\n",
        "\n",
        "      x_k_transposed = x_k.transpose(1, 2)\n",
        "      att_scores = torch.bmm(x_q, x_k_transposed)/sqrt(256)\n",
        "      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "      att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "      attention_vectors = torch.bmm(att_scores, x_v)# тут тоже что то с чем то нужно перемножить :)\n",
        "\n",
        "      x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "      x_cnn3 = self.cnn_3gr(x_att)\n",
        "      x_cnn4 = self.cnn_4gr(x_att)\n",
        "      x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "      frst, _ = x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "      sc, _ = x_cnn4.max(dim= -1,)\n",
        "      thr, _ = x_cnn5.max(dim= -1,)\n",
        "      \n",
        "      x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "      x = self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n",
        "      x = self.relu(x)    \n",
        "      x = self.linear_2(x)\n",
        "    \n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "jFbyUXLE0WPv"
      },
      "outputs": [],
      "source": [
        "n_classes = data.category.unique().shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "OZgh4ONx0HvT"
      },
      "outputs": [],
      "source": [
        "model = model_with_att(vectors, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNO6VSbJgQ36",
        "outputId": "f2d9107d-1006-4fc4-a6ff-836c92e957fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_with_att(\n",
              "  (emb_layer): Embedding(117619, 300)\n",
              "  (LSTM): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
              "  (q_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (k_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (v_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (att_soft): Softmax(dim=2)\n",
              "  (cnn_3gr): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "  (cnn_4gr): Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
              "  (cnn_5gr): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
              "  (linear_1): Linear(in_features=384, out_features=256, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear_2): Linear(in_features=256, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ],
      "source": [
        "model #если сделать batch_first=True, то можно не транспонировать батчи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "E66MWNgM0QKM"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    pred = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "ErboeQbv0dnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b45e0f1-7afe-4887-953c-8a008310dcfa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "bL6zIZSt0h9W"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "Vsxw4M2m0m2B"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rUTc0l60pV9",
        "outputId": "15ac3f07-d115-40ed-e344-8f598fe04de3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [01:15<00:00, 2833.92it/s, train_loss=0.485]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.599, test - 0.492\n",
            "F1 test - 0.821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [01:15<00:00, 2821.25it/s, train_loss=0.449]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.459, test - 0.457\n",
            "F1 test - 0.834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [01:16<00:00, 2800.98it/s, train_loss=0.425]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.430, test - 0.450\n",
            "F1 test - 0.837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [01:16<00:00, 2810.86it/s, train_loss=0.403]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.408, test - 0.448\n",
            "F1 test - 0.839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [01:16<00:00, 2815.18it/s, train_loss=0.381]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.385, test - 0.449\n",
            "F1 test - 0.841\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TMaPbh3oWwc"
      },
      "source": [
        "Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "_aPjTQcR0vm2"
      },
      "outputs": [],
      "source": [
        "for instance in list(tqdm._instances): \n",
        "    tqdm._decr_instances(instance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaDKjKT8LCSG"
      },
      "source": [
        "# Оценка\n",
        "1. Добрались сюда - очень хорошо - получилась такая же точность или около того - 7 баллов.\n",
        "2. Поставили эксперименты и повысили точность относительно своей и не ниже F1 test - 0.841 - 8 баллов.\n",
        "3. Запустили бертовую тетрадку и разобрались. Получился сравнимый результат - 10 баллов "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "e5BgHdtW2sO3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}